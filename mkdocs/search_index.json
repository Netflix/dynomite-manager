{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Dynomite Manager\n\n\nDynomite\n\n\nDynomite is used at Netflix both (a) as a caching layer in front of Cassandra and ElasticSearch, and (b) as a data store layer by itself. The latter is achieved by keeping 9 copies of the data across 3 regions and 3 availability zones (high availability), client failover, as well as by enabling cold bootstrapping (warm up), S3 backups, and other features. Most of these features are enabled through the use of Dynomite-manager (formerly named Florida).\n\n\nDynomite Manager\n\n\nDynomite-manager is a sidecar specifically developed to manage Netflix\u2019s Dynomite clusters and integrate it with the AWS (and Netflix) Ecosystem. It follows similar design principles from more than 6 years of experience of managing Cassandra with Priam, and ElasticSearch clusters with Raigad. Dynomite-manager design is based on Quartz, a rich-featured open source job scheduling library, and Java interfaces such that it can be extensible to other data store engines and cloud deployments (other than Amazon Web Services).", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-dynomite-manager", 
            "text": "", 
            "title": "Welcome to Dynomite Manager"
        }, 
        {
            "location": "/#dynomite", 
            "text": "Dynomite is used at Netflix both (a) as a caching layer in front of Cassandra and ElasticSearch, and (b) as a data store layer by itself. The latter is achieved by keeping 9 copies of the data across 3 regions and 3 availability zones (high availability), client failover, as well as by enabling cold bootstrapping (warm up), S3 backups, and other features. Most of these features are enabled through the use of Dynomite-manager (formerly named Florida).", 
            "title": "Dynomite"
        }, 
        {
            "location": "/#dynomite-manager", 
            "text": "Dynomite-manager is a sidecar specifically developed to manage Netflix\u2019s Dynomite clusters and integrate it with the AWS (and Netflix) Ecosystem. It follows similar design principles from more than 6 years of experience of managing Cassandra with Priam, and ElasticSearch clusters with Raigad. Dynomite-manager design is based on Quartz, a rich-featured open source job scheduling library, and Java interfaces such that it can be extensible to other data store engines and cloud deployments (other than Amazon Web Services).", 
            "title": "Dynomite Manager"
        }, 
        {
            "location": "/AWS-Deployment/", 
            "text": "Environmental Variables:\n\n\nIf you plan to use the default configuration, \nDynomitemanagerConfiguration\n, then the following environmental variables must be setup:\n\n\n\n\nEC2_REGION\n\n\nASG_NAME\n \n\n\nAUTO_SCALE_GROUP\n\n\n\n\nSetting up AWS Roles:\n\n\nIn order to access the AWS services and metadata information, the user must setup the proper IAM roles (for example add a Dynomite role) and on the launch configuration that role can be used. The IAM roles need to have access to iam/security-credentials/ for the following services (depending on the environment)\n\n EC2\n\n S3 (for backups/restores)\n* SimpleDB (if this use as the IConfigSource)\n\n\nS3 Backups and Restores\n\n\nIn order to make backups and restore feature to work, Dynomite-manager must have access to \n/mnt/data\n and the directory must be configured in the configured in the data store configuration (e.g. Redis) as the location of the persisting the data.", 
            "title": "AWS Deployment"
        }, 
        {
            "location": "/AWS-Deployment/#environmental-variables", 
            "text": "If you plan to use the default configuration,  DynomitemanagerConfiguration , then the following environmental variables must be setup:   EC2_REGION  ASG_NAME    AUTO_SCALE_GROUP", 
            "title": "Environmental Variables:"
        }, 
        {
            "location": "/AWS-Deployment/#setting-up-aws-roles", 
            "text": "In order to access the AWS services and metadata information, the user must setup the proper IAM roles (for example add a Dynomite role) and on the launch configuration that role can be used. The IAM roles need to have access to iam/security-credentials/ for the following services (depending on the environment)  EC2  S3 (for backups/restores)\n* SimpleDB (if this use as the IConfigSource)", 
            "title": "Setting up AWS Roles:"
        }, 
        {
            "location": "/AWS-Deployment/#s3-backups-and-restores", 
            "text": "In order to make backups and restore feature to work, Dynomite-manager must have access to  /mnt/data  and the directory must be configured in the configured in the data store configuration (e.g. Redis) as the location of the persisting the data.", 
            "title": "S3 Backups and Restores"
        }, 
        {
            "location": "/Backups-and-Restores/", 
            "text": "Dynomite can be used as a single point of truth (data store) as well as a cache. A dependable backup and recovery process is therefore critical for Disaster Recovery (DR) and Data Corruption (CR) when choosing a data store in the cloud. With Dynomite-manager, a daily snapshot for all clusters that leverage Dynomite as a data store is used to back them up to an object storage. The default implementation is currently S3; S3 was an obvious choice due to its simple interface and ability to access any amount of data from anywhere.\n\n\nHow it works\n\n\nBackup\n:\nDynomite-manager initiates the S3 backups. The backups feature leverages the persistence feature of Redis to dump data to the drive. Dynomite-manager supports both the RDB and the AOF persistence of Redis, offering the ability to the users to use a readable format of their data for debugging or a memory direct snapshot. The backups leverage the IAM credentials in order to encrypt the communication. Backups (a) can be scheduled using a date in the configuration (or by leveraging Archaius, Netflix configuration management API), and (b) on demand using the REST API. \n\n\nRestores\n:\nDynomite-manager supports restoring a single node through a REST API, or the complete ring. When performing a restore, Dynomite-manager (on each node), shuts down Redis and Dynomite, locates the snapshot files in S3, and orchestrates the download of the files. Once the snapshot is transferred to the node, Dynomite-manager starts Redis and waits until the data are in memory, and then follows up with starting the Dynomite process. Dynomite-manager can also restore data to clusters with different names. This allows us to spin up multiple test clusters with the same data, enabling refreshes. Refreshes are very important at Netflix, because cluster users can leverage production data in a test environment, hence perform realistics benchmarks and offline analysis on production data. Finally, Dynomite-manager allows for targeted refreshes on a specific date, allowing cluster users to restore data to point prior to the data corruption, test production data for a specific time frame and opening the doors for many other use cases that we have not yet explored.\n\n\nSetting up backups/restores\n\n\nDynomite-manager uses the fast properties, or external configuration, to define the backup/restore buckets as well as other related properties\n\n\n\n\ndynomitemanager.dyno.backup.bucket.name\n: Object storage bucket name, where backed up files will be stored\n\n\ndynomitemanager.dyno.backup.restore.enabled\n: \nfalse\n by default, enabling restores\n\n\ndynomitemanager.dyno.backup.snapshot.enabled\n: \nfalse\n by default, enabling backups", 
            "title": "Backups and Restores"
        }, 
        {
            "location": "/Backups-and-Restores/#how-it-works", 
            "text": "Backup :\nDynomite-manager initiates the S3 backups. The backups feature leverages the persistence feature of Redis to dump data to the drive. Dynomite-manager supports both the RDB and the AOF persistence of Redis, offering the ability to the users to use a readable format of their data for debugging or a memory direct snapshot. The backups leverage the IAM credentials in order to encrypt the communication. Backups (a) can be scheduled using a date in the configuration (or by leveraging Archaius, Netflix configuration management API), and (b) on demand using the REST API.   Restores :\nDynomite-manager supports restoring a single node through a REST API, or the complete ring. When performing a restore, Dynomite-manager (on each node), shuts down Redis and Dynomite, locates the snapshot files in S3, and orchestrates the download of the files. Once the snapshot is transferred to the node, Dynomite-manager starts Redis and waits until the data are in memory, and then follows up with starting the Dynomite process. Dynomite-manager can also restore data to clusters with different names. This allows us to spin up multiple test clusters with the same data, enabling refreshes. Refreshes are very important at Netflix, because cluster users can leverage production data in a test environment, hence perform realistics benchmarks and offline analysis on production data. Finally, Dynomite-manager allows for targeted refreshes on a specific date, allowing cluster users to restore data to point prior to the data corruption, test production data for a specific time frame and opening the doors for many other use cases that we have not yet explored.", 
            "title": "How it works"
        }, 
        {
            "location": "/Backups-and-Restores/#setting-up-backupsrestores", 
            "text": "Dynomite-manager uses the fast properties, or external configuration, to define the backup/restore buckets as well as other related properties   dynomitemanager.dyno.backup.bucket.name : Object storage bucket name, where backed up files will be stored  dynomitemanager.dyno.backup.restore.enabled :  false  by default, enabling restores  dynomitemanager.dyno.backup.snapshot.enabled :  false  by default, enabling backups", 
            "title": "Setting up backups/restores"
        }, 
        {
            "location": "/Cold-Bootstraping/", 
            "text": "In designing our warm up feature, we considered the following principles:\n\n\n\n\nDo not introduce inconsistencies;\n\n\nDo not achieve a fully warmed up node, but get as many data as possible.\n\n\nDo not create any major issues to another node (i.e. node used as the source of truth)\n\n\n\n\nBased on these principles, a failure of the warm up process should not cause an issue in the cluster, and it should not stop the newly brought up node.\n\n\nThe cold bootstrapping feature is currently designed around Redis. It leverages the master-slave diskless replication of Redis. Dynomite-manager sets the target node that needs to be warmed up as \u201cslave\u201d, and finds another peer with the same token in the local region. That peer is designated as the master, and therefore forces Redis to transfer an rdb file and load it to Redis. Once the warm up is complete then Redis is switched back to serve traffic as a normal master.\n\n\nWarm up or bootstrapping is triggered by a termination of a node. This is in turn causes a new token to be generated, which initiates the warm up process. The following is the sequence of operations:\n\n\n\n\nSearches for the correct token: Warming up node's own token(s) : 1383429731\n\n\nDetermines which peer nodes have the same token. A random peer node within the local region is selected to be used for the warm up which avoids cross-region communication issues.\n\n\nRedis issues \nSLAVEOF\n command to that peer. Effectively the target Redis instance sets itself as a slave of that node. In addition, Dynomite-manager sets Dynomite to be in standby mode so that traffic is not received and the node remains out of discovery.\n\n\nA Dynomite node is fully warmed up if it has received all the data from the remote at the time the warm up process started. To determine if a node is warmed up we use the difference between the Redis master and the Redis slave offset. Both offsets are calculated from the Redis master node that was selected as the source of warm up. This gives us the correct view of how much data the remote Redis master node has streamed and how much data it believes the Redis slave node has received.\n\n\nOnce master and slave are in sync, Dynomite is set to allow writes only.\n\n\nRedis is stopped from peer syncing by using  Redis \u201cSLAVEOF NO ONE\u201d command\n\n\nDynomite is set back to normal state. Process checks health of Dynomite, if there is an issue Dynomite gets restarted.\n\n\nDone!", 
            "title": "Cold Bootstraping"
        }, 
        {
            "location": "/FAQ/", 
            "text": "Here we will posting common questions asked by the community. However, if need some help with either getting up and going or some problems with the code please submit an issue on this github repo.", 
            "title": "FAQ"
        }, 
        {
            "location": "/Features/", 
            "text": "Discovery and Healthcheck\n\n\nNode Configuration and Token Management for multi-region deployments\n\n\nDynomite/Redis cold bootstrap (warm up)\n\n\nMonitoring and Insights Integration\n\n\nSupport multi-region Dynomite deployment via public IP.\n\n\nAutomated security group update in multi-region environment.\n\n\nObject storage backups (AWS S3 implenentation provided)\n\n\nREST API", 
            "title": "Features"
        }, 
        {
            "location": "/Getting-Started/", 
            "text": "Dynomite Manager Configuration\n\n\nDynomite-manager leverages \nGuice\n to reduce repetition and in favor of a more readable configuration. The registration of the listener takes place in the \nweb.xml\n. \nInjectedWebListener\n is the logical place where the injectors are created and configured. \n\n\nFunctional Areas\n\n\n\n\n\n\n\n\nConfiguration\n\n\nInterface\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nProperties\n\n\nIConfiguration\n\n\nsystem level configuration can be passed. It leverages a file, or \nArchaius\n.\n\n\n\n\n\n\nApplication\n\n\nIAppsInstanceFactory\n\n\ncreate, delete, update etc. instance level operations like application name, instance ID, hostname, IP address, Rack, attached Volumes and Tokens. This information can be stored in an external location.\n\n\n\n\n\n\nStorage\n\n\nIStorageProxy\n\n\nstorage related functionalities like warm up, healthcheck, taking disk snapshot etc.\n\n\n\n\n\n\nEnvironment\n\n\nInstanceDataRetriever\n\n\nreceive information about Rac, public hostname, public IP, Instance ID and type. Mainly these are reported by the environment.\n\n\n\n\n\n\nFast Properties\n\n\nIConfigSource\n\n\nconfiguration source, internally at Netflix we use \nArchaius\n.\n\n\n\n\n\n\n\n\nDefault Implementation\n\n\nbinder().bind(IConfiguration.class).to(DynomitemanagerConfiguration.class);\nbinder().bind(ProcessTuner.class).to(FloridaStandardTuner.class);\nbinder().bind(IAppsInstanceFactory.class).to(CassandraInstanceFactory.class);\nbinder().bind(SchedulerFactory.class).to(StdSchedulerFactory.class).asEagerSingleton();\nbinder().bind(ICredential.class).to(IAMCredential.class);\nbinder().bind(IFloridaProcess.class).to(FloridaProcessManager.class);\nbinder().bind(IStorageProxy.class).to(RedisStorageProxy.class);\nbinder().bind(InstanceDataRetriever.class).to(AwsInstanceDataRetriever.class);\n\n\n\nHowever, one can implement the interfaces based on their deployment and environment. The following implementations are provided:\n\n\n\n\nDynomitemanagerConfiguration\n contains the default configuration properties. Properties inherently use \nArchaius\n configuration.\n\n\nFloridaStandardTuner\n contains the configuration to be written in the dynomite.yml file. More information about the yml file can be found in the \nDynomite repo\n.\n\n\nCassandraInstanceFactory\n provides an implementation in Cassandra for token management. The configuration of the Cassandra cluster is defined in the \nDynomitemanagerConfiguration\n\n\nStdSchedulerFactory is the standard Quartz scheduler implementation.\n\n\nIAMCredential\n credentials provided by the AWS and instance credentials provider.\n\n\nFloridaProcessManager\n is the administrative process for Dynomite (start, stop, write-only etc.)\n\n\nRedisStorageProxy\n handles the Redis storage level. The implementations for Redis is complete, further storage deployments can be added in \nstorage package\n\n\nAwsInstanceDataRetriever\n provides information about the instance from AWS. Implementations for VPC and local deployments are provided in the \nconfig package\n. For running Dynomite Manager locally in your system, you can use \nLocalInstanceDataRetriever\n.\n\n\nSimpleDBConfigSource\n provides an interface to store and retrieve configuration information using SimpleDB. Further implementations on how to use \n\n\n\n\nHost Supplier\n\n\nOne can provide its own host supplier. In this case the \nconfig.isEurekaHostSupplierEnabled()\n must return \nfalse\n.\n\n\nThere are two exemplar host suppliers in the corresponding \npackage\n. One based on Eureka and one based on a locally provided host supplier.\n\n\nHow to Use Configuration source:\n\n\nProperties inherently use \nArchaius\n configuration.\n\n\nBut you can use any of the above methods to supply properties whichever way you would like. (e.g. \nDynomitemanager.properties\n or System properties)\n\n\nAnother way\n to provide your properties is by using dynomitemanager{version}.jar in your web container and \nthen implementing IConfiguration interface.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/Getting-Started/#dynomite-manager-configuration", 
            "text": "Dynomite-manager leverages  Guice  to reduce repetition and in favor of a more readable configuration. The registration of the listener takes place in the  web.xml .  InjectedWebListener  is the logical place where the injectors are created and configured.", 
            "title": "Dynomite Manager Configuration"
        }, 
        {
            "location": "/Getting-Started/#functional-areas", 
            "text": "Configuration  Interface  Description      Properties  IConfiguration  system level configuration can be passed. It leverages a file, or  Archaius .    Application  IAppsInstanceFactory  create, delete, update etc. instance level operations like application name, instance ID, hostname, IP address, Rack, attached Volumes and Tokens. This information can be stored in an external location.    Storage  IStorageProxy  storage related functionalities like warm up, healthcheck, taking disk snapshot etc.    Environment  InstanceDataRetriever  receive information about Rac, public hostname, public IP, Instance ID and type. Mainly these are reported by the environment.    Fast Properties  IConfigSource  configuration source, internally at Netflix we use  Archaius .", 
            "title": "Functional Areas"
        }, 
        {
            "location": "/Getting-Started/#default-implementation", 
            "text": "binder().bind(IConfiguration.class).to(DynomitemanagerConfiguration.class);\nbinder().bind(ProcessTuner.class).to(FloridaStandardTuner.class);\nbinder().bind(IAppsInstanceFactory.class).to(CassandraInstanceFactory.class);\nbinder().bind(SchedulerFactory.class).to(StdSchedulerFactory.class).asEagerSingleton();\nbinder().bind(ICredential.class).to(IAMCredential.class);\nbinder().bind(IFloridaProcess.class).to(FloridaProcessManager.class);\nbinder().bind(IStorageProxy.class).to(RedisStorageProxy.class);\nbinder().bind(InstanceDataRetriever.class).to(AwsInstanceDataRetriever.class);  However, one can implement the interfaces based on their deployment and environment. The following implementations are provided:   DynomitemanagerConfiguration  contains the default configuration properties. Properties inherently use  Archaius  configuration.  FloridaStandardTuner  contains the configuration to be written in the dynomite.yml file. More information about the yml file can be found in the  Dynomite repo .  CassandraInstanceFactory  provides an implementation in Cassandra for token management. The configuration of the Cassandra cluster is defined in the  DynomitemanagerConfiguration  StdSchedulerFactory is the standard Quartz scheduler implementation.  IAMCredential  credentials provided by the AWS and instance credentials provider.  FloridaProcessManager  is the administrative process for Dynomite (start, stop, write-only etc.)  RedisStorageProxy  handles the Redis storage level. The implementations for Redis is complete, further storage deployments can be added in  storage package  AwsInstanceDataRetriever  provides information about the instance from AWS. Implementations for VPC and local deployments are provided in the  config package . For running Dynomite Manager locally in your system, you can use  LocalInstanceDataRetriever .  SimpleDBConfigSource  provides an interface to store and retrieve configuration information using SimpleDB. Further implementations on how to use", 
            "title": "Default Implementation"
        }, 
        {
            "location": "/Getting-Started/#host-supplier", 
            "text": "One can provide its own host supplier. In this case the  config.isEurekaHostSupplierEnabled()  must return  false .  There are two exemplar host suppliers in the corresponding  package . One based on Eureka and one based on a locally provided host supplier.", 
            "title": "Host Supplier"
        }, 
        {
            "location": "/Getting-Started/#how-to-use-configuration-source", 
            "text": "Properties inherently use  Archaius  configuration.  But you can use any of the above methods to supply properties whichever way you would like. (e.g.  Dynomitemanager.properties  or System properties)  Another way  to provide your properties is by using dynomitemanager{version}.jar in your web container and \nthen implementing IConfiguration interface.", 
            "title": "How to Use Configuration source:"
        }, 
        {
            "location": "/Home/", 
            "text": "Dynomite-manager Wiki\n\n\nDynomite\n is used at Netflix both (a) as a caching layer in front of Cassandra and ElasticSearch, and (b) as a data store layer by itself. The latter is achieved by keeping 9 copies of the data across 3 regions and 3 availability zones (high availability), client failover, as well as by enabling cold bootstrapping (warm up), S3 backups, and other features. Most of these features are enabled through the use of Dynomite-manager (formerly named Florida).\n\n\nDynomite-manager\n is a sidecar specifically developed to manage Netflix\u2019s Dynomite clusters and integrate it with the AWS (and Netflix) Ecosystem. It follows similar design principles from more than 6 years of experience of managing Cassandra with Priam, and ElasticSearch clusters with Raigad. Dynomite-manager design is based on Quartz, a rich-featured open source job scheduling library, and Java interfaces such that it can be extensible to other data store engines and cloud deployments (other than Amazon Web Services).", 
            "title": "Home"
        }, 
        {
            "location": "/Home/#dynomite-manager-wiki", 
            "text": "Dynomite  is used at Netflix both (a) as a caching layer in front of Cassandra and ElasticSearch, and (b) as a data store layer by itself. The latter is achieved by keeping 9 copies of the data across 3 regions and 3 availability zones (high availability), client failover, as well as by enabling cold bootstrapping (warm up), S3 backups, and other features. Most of these features are enabled through the use of Dynomite-manager (formerly named Florida).  Dynomite-manager  is a sidecar specifically developed to manage Netflix\u2019s Dynomite clusters and integrate it with the AWS (and Netflix) Ecosystem. It follows similar design principles from more than 6 years of experience of managing Cassandra with Priam, and ElasticSearch clusters with Raigad. Dynomite-manager design is based on Quartz, a rich-featured open source job scheduling library, and Java interfaces such that it can be extensible to other data store engines and cloud deployments (other than Amazon Web Services).", 
            "title": "Dynomite-manager Wiki"
        }, 
        {
            "location": "/How-to-contribute/", 
            "text": "Please see \nCONTRIBUTING\n.", 
            "title": "How to contribute"
        }, 
        {
            "location": "/Monitoring-and-Insights-Integration/", 
            "text": "Dynomite-manager exports the statistics of Dynomite and Redis to Atlas for plotting and time-series analysis. We use a tiered architecture for our monitoring system. \n\n\n\n\nDynomite-manager receives information about Dynomite through a REST call;\n\n\nDynomite-manager receives information about Redis through the \nINFO\n command.\n\n\n\n\nCurrently, Dynomite-manager leverages the Servo client to publish the metrics for time series processing. Nonetheless, other Insight clients can be added in order to deliver metrics to a different Insight system.", 
            "title": "Monitoring and Insights Integration"
        }, 
        {
            "location": "/REST-API/", 
            "text": "REST API\n\n\nThe default prefix used in Dynomite Manager is as follows \n\n\nhttp://localhost:8080/REST/v1/admin\n\n\nThe following operations are currently implemented in \nDynomiteAdmin\n, which is the central location for the REST calls\n\n\n\n\n/start\n: starts Dynomite\n\n\n/stop\n: stops Dynomite\n\n\n/startstorageprocess\n: starts storage process\n\n\n/stopstorageprocess\n: stops storage process\n\n\n/get_seeds\n: responds with the hostnames and tokens\n\n\n/cluster_describe\n: responds with a JSON file of the cluster level information\n\n\n/backup\n: forces an S3 backups\n\n\n/restore\n:  forces an S3 restore\n\n\n/takesnapshot\n: persist the storage data (if Redis) to the drive (based on configuration properties, this can be RDB or AOF)\n\n\n/status\n:  returns the status of the processes managed by Dynomitemanager and itself.\n\n\n\n\nExample\n\n\ncurl http://localhost:8080/REST/v1/admin/status", 
            "title": "REST API"
        }, 
        {
            "location": "/REST-API/#rest-api", 
            "text": "The default prefix used in Dynomite Manager is as follows   http://localhost:8080/REST/v1/admin  The following operations are currently implemented in  DynomiteAdmin , which is the central location for the REST calls   /start : starts Dynomite  /stop : stops Dynomite  /startstorageprocess : starts storage process  /stopstorageprocess : stops storage process  /get_seeds : responds with the hostnames and tokens  /cluster_describe : responds with a JSON file of the cluster level information  /backup : forces an S3 backups  /restore :  forces an S3 restore  /takesnapshot : persist the storage data (if Redis) to the drive (based on configuration properties, this can be RDB or AOF)  /status :  returns the status of the processes managed by Dynomitemanager and itself.", 
            "title": "REST API"
        }, 
        {
            "location": "/REST-API/#example", 
            "text": "curl http://localhost:8080/REST/v1/admin/status", 
            "title": "Example"
        }, 
        {
            "location": "/Service-Discovery-and-Healthcheck/", 
            "text": "Healthcheck\n\n\nDynomite-manager schedules a Quartz (lightweight thread) every 15 seconds that checks the health of both Dynomite and the underlying storage engine. Since most of our current production deployments leverage Redis, or storage engines based on Redis Serialization Protocol (RESP), the healthcheck involves a three step approach. \n\n\n\n\nCheck if Dynomite and Redis are running as Linux processes. \n\n\nCheck if Dynomite can listen to a Redis \nPING\n and respond to a Redis \nPONG\n. This step ensures that the neither Dynomite nor Redis are zombie processes and are operational.\n\n\nCheck if Dynomite can respond \nOK\n to a Redis \nSETEX\n with 1 second TTL. We use \nSETEX\n because we can expire the key without needed to fire another delete. This step ensures that although Dynomite and Redis are operational, they can still write traffic, which is not the case if the available memory has been exhausted or Redis for some reason runs in slave mode. \n\n\n\n\nDiscovery\n\n\nIf any of the above checks are not satisfied, Dynomite-manager informs Eureka (Netflix Service registry for resilient mid-tier load balancing and failover) and the node is removed from Discovery. This ensures that the Dyno client can gracefully failover the traffic to another Dynomite node with the same token.", 
            "title": "Service Discovery and Healthcheck"
        }, 
        {
            "location": "/Service-Discovery-and-Healthcheck/#healthcheck", 
            "text": "Dynomite-manager schedules a Quartz (lightweight thread) every 15 seconds that checks the health of both Dynomite and the underlying storage engine. Since most of our current production deployments leverage Redis, or storage engines based on Redis Serialization Protocol (RESP), the healthcheck involves a three step approach.    Check if Dynomite and Redis are running as Linux processes.   Check if Dynomite can listen to a Redis  PING  and respond to a Redis  PONG . This step ensures that the neither Dynomite nor Redis are zombie processes and are operational.  Check if Dynomite can respond  OK  to a Redis  SETEX  with 1 second TTL. We use  SETEX  because we can expire the key without needed to fire another delete. This step ensures that although Dynomite and Redis are operational, they can still write traffic, which is not the case if the available memory has been exhausted or Redis for some reason runs in slave mode.", 
            "title": "Healthcheck"
        }, 
        {
            "location": "/Service-Discovery-and-Healthcheck/#discovery", 
            "text": "If any of the above checks are not satisfied, Dynomite-manager informs Eureka (Netflix Service registry for resilient mid-tier load balancing and failover) and the node is removed from Discovery. This ensures that the Dyno client can gracefully failover the traffic to another Dynomite node with the same token.", 
            "title": "Discovery"
        }, 
        {
            "location": "/Step-by-step-installation/", 
            "text": "AWS Deployment\n\n\nAuthor: \nDiego Pacheco\n\n\nInstall Cassandra for Token Management\n\n\nInstall java 8\n\n\n# Remove java 7\nsudo yum remove -y java\n\n# Install basic packages\nsudo yum install -y git\n\n# Download and install java 8\nwget --no-cookies --no-check-certificate --header \nCookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\n \nhttp://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.tar.gz\n\ntar -xzvf jdk-8u45-linux-x64.tar.gz\nrm -rf jdk-8u45-linux-x64.tar.gz\n\n# Configure JAVA_HOME\nsudo vim ~/.bashrc\n\n\n\n\nalias cls='clear'\n\nexport JAVA_HOME=~/jdk1.8.0_45\nexport JRE_HOME=~/jdk1.8.0_45/jre\nexport PATH=$PATH:~/jdk1.8.0_45/bin:/~/jdk1.8.0_45/jre/bin\n\n\n\n\nsource ~/.bashrc \njava -version\n\n\n\n\nCassandra 2.x\n\n\nwget https://archive.apache.org/dist/cassandra/2.1.9/apache-cassandra-2.1.9-bin.tar.gz\ntar -xzvf apache-cassandra-2.1.9-bin.tar.gz\nrm -rf apache-cassandra-2.1.9-bin.tar.gz\n\n\n\n\nConfigure the Cassandra Cluster\n\n\n# your_server_ip - copy the IP\nhostname -i\nvim ~/apache-cassandra-2.1.9/conf/cassandra.yaml\n\n\n\n\ncluster_name: 'Test Cluster'\nlisten_address: your_server_ip\nrpc_address: your_server_ip\nseed_provider:\n  - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n    parameters:\n         - seeds: \nip1,ip2,...ipN\n\nendpoint_snitch: GossipingPropertyFileSnitch\n\n\n\n\nStart up the Cassandra cluster\n\n\n# on each Cassandra node... \ncd ~/apache-cassandra-2.1.9\nbin/cassandra start\n\n\n\n\nOpen EC2 Security Group ports\n\n\n7000\n9160\n9042\n\n\n\n\nTest data replication with \ncqlsh\n\n\n# Connect to any node - you can run: hostname -i to get the IP\napache-cassandra-2.1.9/bin/cqlsh IP\n\n\n\n\nCREATE KEYSPACE CLUSTER_TEST WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 }; \nUSE CLUSTER_TEST;\nCREATE TABLE TEST ( key text PRIMARY KEY, value text);\nINSERT INTO TEST (key,value) VALUES ('1', 'works');\nSELECT * from TEST;\n\n\n\n\n# Connect to any other node - you can run: hostname -i to get the IP - check for data replication\napache-cassandra-2.1.9/bin/cqlsh IP\nUSE CLUSTER_TEST;\nSELECT * from TEST;\n\n\n\n\nCreate a AWS Role called: dynomite\n\n\nGoto Identity and Access Management(https://console.aws.amazon.com/iam/home?region=us-west-2#roles) at Roles.\n \nCreate a new role called: dynomite and add the policies: \n\n\n\n   \nAmazonEC2FullAccess\n   \nAmazonS3FullAccess\n   \nIAMFullAccess\n\n\n\nCreate S3 bucket\n\n\nGoto S3(https://console.aws.amazon.com/s3/home?region=us-west-2#) and create bucket called: dynomite-backup.\nGoto Properties-\n Permissions and them add: Any Authenticated AWS User (List, Upload/Delete/View/Edit).\n\n\nSetup Dynomite and Dynomite Manager + Build an AMI\n\n\n2.1. Create a Amazon Linux AMI Box \n\n2.1.1. Select The Instance type: m4.large Or anything you like it. \n\n2.1.2. Configure the Instance Details: IAM Roles: IAM role \n\n2.1.3. Configure the Instance Details: Monitoring - Mark Enable CloudWatch detailed monitoring \n\n2.1.4. Add Storage: 20Gb storare Or anything you like it.  \n\n2.1.5. Tag Instance: dynomite_dynomitemanager \n\n2.1.6. Configure Security Group: sg_asg_dynomite_florida with rules: \n\nEnable TCP: \n\n\n\n  \n22\n  \n8080\n  \n8000 - 8100 (for debug)\n  \n8101 - 8102(dynomite) \n  \n7000 (cassandra) \n  \n9160 (cassandra) \n  \n9042 (cassandra) \n\n  \n\n\nThis could vary depending of your VPC config because \n\nyou might need add several rules dependeing how my ips you need to allow. But this are the ports you need be enable. \n\n\n2.1.7. Pick whatever PEM file do you want. Finish the Box creation and SSH to the box. \n\n3. Installing Dynomite, Redis, Dynomite-Manager and Cassandra\n\n\nLet's update the OS first.\n\n\nsudo yum update -y\n\n\n\n\nLet's setup Java JDK 8(Needed by Dynomite Manager).\n\n\nsudo yum remove java -y\nsudo wget --no-cookies --no-check-certificate --header \nCookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\n \nhttp://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.tar.gz\n\ntar -xzvf jdk-8u45-linux-x64.tar.gz\nrm -rf jdk-8u45-linux-x64.tar.gz\n\n\n\n\nWe also need export JAVA OS env vars. Let's edit /etc/profile and add:\n\n\nexport JAVA_HOME=/home/ec2-user/jdk1.8.0_45\nexport JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\nexport PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\n\nalias cls=clear\nalias dlog='tail -f -n 2000  /logs/system/dynomite/dynomite.log'\nalias dmlog='tail -f -n 2000 /logs/system/dynomite-manager/dynomite-manager.log'\nalias rlog='tail -f -n 2000 /var/log/redis_22122.log'\nalias clog='tail -f -n 2000 /home/ec2-user/apache-cassandra-2.1.9/logs/system.log'\nalias dgrep='ps aux | grep dynomite'\nalias rcli='redis-cli -p 8102'\nalias dconf='cat /apps/dynomite/conf/dynomite.yml'\n\n\n\n\nAs you can see we also added some bash alias to make your life easier. :-) \n \n\n\nWe need to source this file in order to have the variables and alias available, do:\n\n\nsource /etc/profile\n\n\n\n\nLet's move to dynomite now. Let's Download and Build it.\n\n\nsudo yum install git -y\ngit clone https://github.com/Netflix/dynomite.git\ncd dynomite\nsudo yum install -y autoconf automake\nsudo yum install -y libtool\nsudo yum install -y openssl-devel\nautoreconf -fvi\n./configure --enable-debug=log\nmake\n\n\n\n\nIn order to test Dynomite Installation just run:\n\n\nsrc/dynomite -h\n\n\n\n\nYou should see something like:\n\n\n[ec2-user@ip-172-31-14-210 dynomite]$ src/dynomite -h\nThis is dynomite-alloc_msg_leak-130-g68683f0\n\nUsage: dynomite [-?hVdDt] [-v verbosity level] [-o output file]\n                  [-c conf file] [-s stats port] [-a stats addr]\n                  [-i stats interval] [-p pid file] [-m mbuf size]\n                  [-M max alloc messages]\n\nOptions:\n  -h, --help             : this help\n  -V, --version          : show version and exit\n  -t, --test-conf        : test configuration for syntax errors and exit\n  -g, --gossip           : enable gossip (default: disable)\n  -d, --daemonize        : run as a daemon\n  -D, --describe-stats   : print stats description and exit\n  -v, --verbosity=N            : set logging level (default: 5, min: 0, max: 11)\n  -o, --output=S               : set logging file (default: stderr)\n  -c, --conf-file=S            : set configuration file (default: conf/dynomite.yml)\n  -s, --stats-port=N           : set stats monitoring port (default: 22222)\n  -a, --stats-addr=S           : set stats monitoring ip (default: 0.0.0.0)\n  -i, --stats-interval=N       : set stats aggregation interval in msec (default: 30000 msec)\n  -p, --pid-file=S             : set pid file (default: off)\n  -m, --mbuf-size=N            : set size of mbuf chunk in bytes (default: 16384 bytes)\n  -M, --max-msgs=N             : set max number of messages to allocate (default: 200000)\n  -x, --admin-operation=N      : set size of admin operation (default: 0)\n\n\n\n\n\nAdding the Dynomite config. \n\n\nsudo mkdir -p /apps/dynomite/conf/\nsudo vim /apps/dynomite/conf/dynomite.yml\n\n\n\n\nWith the content:\n\n\ndyn_o_mite:\n  dyn_listen: 0.0.0.0:8101\n  data_store: 0\n  listen: 0.0.0.0:8102\n  dyn_seed_provider: florida_provider\n  servers:\n    - 127.0.0.1:22122:1\n  tokens: '1383429731'\n  auto_eject_hosts: true\n  rack: null\n  distribution: vnode\n  gos_interval: 10000\n  hash: murmur\n  preconnect: true\n  server_retry_timeout: 30000\n  timeout: 5000\n  secure_server_option: datacenter\n  datacenter: us-west-2\n  read_consistency: DC_ONE\n  write_consistency: DC_ONE\n  pem_key_file: /apps/dynomite/conf/dynomite.pem\n\n\n\n\n\nLet's create a startup script for Dynomite.\n\n\nsudo touch /etc/init.d/dynomite\nsudo vim /etc/init.d/dynomite\n\n\n\n\nWith the content:\n\n\n#!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: dynomite\n\nstart() {\n   echo \nstarting dynomite... \n\n   cd /apps/dynomite/\n   sudo bin/dynomite -d -c /apps/dynomite/conf/dynomite.yml -m16384 -M200000 --output=/logs/system/dynomite/dynomite.log \n\n}\n\nstop() {\n   echo \nstop\n\n   PID=`pgrep dynomite`\n   if [[ \n !=  \n$PID\n ]]; then\n      echo \nkilling $PID\n\n      kill -9 $PID\n   fi\n}\n\ncase \n$1\n in start)\n  start\n;;\n  stop)\n  stop\n;;\n*)\n\necho $\nUsage: $0 {start|stop}\n\nRETVAL=1\nesac\nexit 0\n\n\n\n\n\nNow we need add permissions to execute and put it on the startup of the box.\n\n\nsudo chmod +x /etc/init.d/dynomite\nsudo chkconfig dynomite off\n\n\n\n\nOK. Next step is install Redis 3.X.\n\n\ncd ..\nsudo yum install -y gcc*\nsudo yum install -y tcl\nwget http://download.redis.io/releases/redis-3.0.4.tar.gz\ntar xzf redis-3.0.4.tar.gz\ncd redis-3.0.4\ncd deps ; make hiredis jemalloc linenoise lua ; cd ..\nmake\nmake test\nsudo make install\ncd utils ; sudo chmod +x install_server.sh ; sudo ./install_server.sh\n\n\n\n\nThe last command will start the redis installer you will need anwser the questions as I did it here:\n\n\nWelcome to the redis service installer\nThis script will help you easily set up a running redis server\n\nPlease select the redis port for this instance: [6379] 22122\nPlease select the redis config file name [/etc/redis/22122.conf] /apps/nfredis/conf/redis.conf\nPlease select the redis log file name [/var/log/redis_22122.log] /var/log/redis_22122.log\nPlease select the data directory for this instance [/var/lib/redis/22122] /mnt/data/nfredis/\nPlease select the redis executable path [] /usr/local/bin/redis-server\nSelected config:\nPort           : 22122\nConfig file    : /apps/nfredis/conf/redis.conf\nLog file       : /var/log/redis_22122.log\nData dir       : /mnt/data/nfredis/\nExecutable     : /usr/local/bin/redis-server\nCli Executable : /usr/local/bin/redis-cli\nIs this ok? Then press ENTER to go on or Ctrl-C to abort.\nCopied /tmp/22122.conf =\n /etc/init.d/redis_22122\nInstalling service...\nSuccessfully added to chkconfig!\nSuccessfully added to runlevels 345!\nStarting Redis server...\nInstallation successful!\n\n\n\n\nAfter the installation we should test your Redis installation doing this:\n\n\ncd ~\nrm -rf redis-3.0.4.tar.gz\n\n[ec2-user@ip-172-31-14-210 utils]$ redis-cli\nCould not connect to Redis at 127.0.0.1:6379: Connection refused\nnot connected\n \n[ec2-user@ip-172-31-14-210 utils]$ redis-cli -p 22122\n127.0.0.1:22122\n set k1 redis\nOK\n127.0.0.1:22122\n get k1\n\nredis\n\n127.0.0.1:22122\n \n\n\n\n\nSince Redis is working we can test Dynomite as Well. Dynomite is RESP compatible let's test ddynomite using the standard\n redis client. Redis is on the port 21222 and dynomite on 8102.\n\n\n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122\n set k1 redis\nOK\n127.0.0.1:22122\n get k1\n\nredis\n\n127.0.0.1:22122\n \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122\n get k1\n\nredis\n\n127.0.0.1:22122\n \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 8102\n127.0.0.1:8102\n get k1\n\nredis\n\n127.0.0.1:8102\n set k1 dynomite\nOK\n127.0.0.1:8102\n get k1\n\ndynomite\n\n127.0.0.1:8102\n \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122\n get k1\n\ndynomite\n\n127.0.0.1:22122\n \n\n\n\n\nWe also can check the log using our bash alias dlog.\n\n\n     #                                      m                        \n  mmm#  m   m  mmmm    mmm   mmmmm  mmm    mm#mm   mmm                \n #   #  \\m m/  #   #  #   #  # # #    #      #    #   #               \n #   #   #m#   #   #  #   #  # # #    #      #    #''''               \n \\#m##   \\#    #   #   #m#   # # #  mm#mm    mm    #mm                \n         m/                                \n[2016-06-25 18:59:25.557] stats_listen:1294 m 5 listening on '0.0.0.0:22222'\n[2016-06-25 18:59:25.557] entropy_key_iv_load:365 Key File name: conf/recon_key.pem - IV File name: conf/recon_iv.pem\n[2016-06-25 18:59:25.558] entropy_key_iv_load:420 key loaded: 0123456789012345\n[2016-06-25 18:59:25.558] entropy_key_iv_load:428 iv loaded: 0123456789012345\n[2016-06-25 18:59:25.558] entropy_listen:329 anti-entropy m 9 listening on '127.0.0.1:8105'\n[2016-06-25 18:59:25.558] conn_connect:525 connected to '127.0.0.1:22122:1' on p 12\n[2016-06-25 18:59:25.558] proxy_init:124 p 13 listening on '0.0.0.0:8102' in redis pool 'dyn_o_mite'\n[2016-06-25 18:59:25.558] dnode_init:108 dyn: p 14 listening on '0.0.0.0:8101' in redis pool 'dyn_o_mite' with 14615920 servers\n[2016-06-25 18:59:25.558] preselect_remote_rack_for_replication:1803 my rack index 0\n[2016-06-25 18:59:28.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33040'\n[2016-06-25 18:59:28.756] _msg_get:286 alloc_msg_count: 1 caller: req_get conn: CLIENT sd: 15\n[2016-06-25 18:59:28.756] _msg_get:286 alloc_msg_count: 2 caller: rsp_get conn: SERVER sd: 12\n[2016-06-25 18:59:28.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:28.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 18:59:43.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33046'\n[2016-06-25 18:59:43.757] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:43.757] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 18:59:58.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33054'\n[2016-06-25 18:59:58.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:58.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:03.515] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33058'\n[2016-06-25 19:00:13.756] proxy_accept:220 accepted CLIENT 16 on PROXY 13 from '127.0.0.1:33062'\n[2016-06-25 19:00:13.756] core_close_log:307 close CLIENT 16 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:13.756] client_unref_internal_try_put:124 unref conn 0xdf9bb0 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:18.768] conn_recv_data:614 recv on sd 15 eof rb 77 sb 30\n[2016-06-25 19:00:18.768] core_close_log:307 close CLIENT 15 '127.0.0.1:33058' on event 00FF eof 1 done 1 rb 77 sb 30  \n[2016-06-25 19:00:18.768] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:28.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33068'\n[2016-06-25 19:00:28.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:28.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:43.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33076'\n[2016-06-25 19:00:43.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:43.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n\n\n\n\nWe can check Redis log too. With the bash alias rlog.\n\n\n[ec2-user@ip-172-31-31-8 dynomite-manager-1]$ rlog \n19899:M 29 Jun 02:27:47.411 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.0.4 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 22122\n |    `-._   `._    /     _.-'    |     PID: 19899\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n19899:M 29 Jun 02:27:47.411 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n19899:M 29 Jun 02:27:47.411 # Server started, Redis version 3.0.4\n19899:M 29 Jun 02:27:47.411 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n19899:M 29 Jun 02:27:47.411 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never \n /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n19899:M 29 Jun 02:27:47.411 * DB loaded from disk: 0.000 seconds\n19899:M 29 Jun 02:27:47.411 * The server is now ready to accept connections on port 22122\n\n\n\n\nIt's time to Download, Build and Install Dynomite Manager\n\n\ncd ~\ngit clone git@github.com:Netflix/dynomite-manager.git\ncd dynomite-manager-1/\n./gradlew clean build\n\n\n\n\nIF works you will see something like this:\n\n\n:dynomitemanager:processResources\n:dynomitemanager:classes\n:dynomitemanager:writeManifestProperties\n:dynomitemanager:jar\n:dynomitemanager:assemble\n:dynomitemanager-web:compileJava UP-TO-DATE\n:dynomitemanager-web:processResources UP-TO-DATE\n:dynomitemanager-web:classes UP-TO-DATE\n:dynomitemanager-web:writeManifestProperties\n:dynomitemanager-web:war\nDownload https://jcenter.bintray.com/xerces/xercesImpl/2.4.0/xercesImpl-2.4.0.pom\nDownload https://jcenter.bintray.com/xerces/xercesImpl/2.4.0/xercesImpl-2.4.0.jar\n:dynomitemanager-web:assemble\n:collectNetflixOSS\n:dynomitemanager:writeLicenseHeader\n:dynomitemanager:licenseMain\nMissing header in: dynomitemanager/src/main/resources/log4j.properties\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/AwsInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/DefaultVpcInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/LocalInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/InstanceEnvIdentity.java\n:dynomitemanager:licenseTest UP-TO-DATE\n:dynomitemanager:license\n:dynomitemanager:compileTestJava UP-TO-DATE\n:dynomitemanager:processTestResources UP-TO-DATE\n:dynomitemanager:testClasses UP-TO-DATE\n:dynomitemanager:test UP-TO-DATE\n:dynomitemanager:check\n:dynomitemanager:build\n:dynomitemanager-web:writeLicenseHeader\n:dynomitemanager-web:licenseMain UP-TO-DATE\n:dynomitemanager-web:licenseTest UP-TO-DATE\n:dynomitemanager-web:license UP-TO-DATE\n:dynomitemanager-web:compileTestJava UP-TO-DATE\n:dynomitemanager-web:processTestResources UP-TO-DATE\n:dynomitemanager-web:testClasses UP-TO-DATE\n:dynomitemanager-web:test UP-TO-DATE\n:dynomitemanager-web:check UP-TO-DATE\n:dynomitemanager-web:build\n\nBUILD SUCCESSFUL\n\nTotal time: 2 mins 7.695 secs\n\nThis build could be faster, please consider using the Gradle Daemon: https://docs.gradle.org/2.12/userguide/gradle_daemon.html\n[ec2-user@ip-172-31-14-210 dynomite-manager-1]$ \n\n\n\n\nNow we need add the startup script for Dynomite-Manager. Let' create the file first and them add content:\n\n\nsudo touch /etc/init.d/dynomite-manager\nsudo vim /etc/init.d/dynomite-manager\n\n\n\n\n/etc/init.d/dynomite-manager\n\n\n#!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: java\n\nexport JAVA_HOME=/home/ec2-user/jdk1.8.0_45\nexport JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\nexport PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\nexport DM_CASSANDRA_CLUSTER_SEEDS=\nIp1,ip2,ip3\n\n\nexport ASG_NAME=\nasg_dynomite\n\nexport EC2_REGION=\nus-west-2\n\nexport AUTO_SCALE_GROUP=\nasg_dynomite\n\nexport NETFLIX_APP=\nsg_asg_dynomite_florida\n\n\nstart() {\n   echo \nStarting Dynomite Manager...\n\n   cd /home/ec2-user/dynomite-manager-1/\n   /home/ec2-user/dynomite-manager-1/gradlew jettyRun \n /logs/system/dynomite-manager/dynomite-manager.log \n \n}\n\nstop() {\n   echo \nstoping Dynomite Manager... \n\n   PID=`ps -ef | grep gradlew | awk '{print $2}' ORS=' ' | awk '{print $1}'`\n   if [[ \n !=  \n$PID\n ]]; then\n      echo \nkilling $PID\n\n      sudo kill -9 $PID\n   fi\n}\n\ndebug() {\n   echo \nStarting Dynomite Manager for DEBUG...\n\n   cd /home/ec2-user/dynomite-manager-1/\n   export GRADLE_OPTS=\n-Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n\n\n   ./gradlew jettyRun \n   \n}\n\n\ncase \n$1\n in\n\nstart\n)\n  start\n;;\n\ndebug\n)\n  debug\n;;\n \nstop\n)\n  stop\n;;\n*)\n\necho $\nUsage: $0 {start|stop|debug}\n\nRETVAL=1\nesac\nexit 0\n\n\n\n\n\nYou need set your comma separeted Cassandra seeds on DM_CASSANDRA_CLUSTER_SEEDS var.\nWe also need add permissions and need to enable this script to auto boot up with the box.\n\n\nsudo chmod +x /etc/init.d/dynomite-manager\nsudo chkconfig dynomite-manager on\n\n\n\n\nTo make sure it works you can check it.\n\n\nsudo chkconfig --list\n\n\n\n\nYou should see dynomite Manager on the list.\n\n\n[ec2-user@ip-172-31-20-132 ~]$ sudo chkconfig --list\nacpid           0:off   1:off   2:on    3:on    4:on    5:on    6:off\natd             0:off   1:off   2:off   3:on    4:on    5:on    6:off\nauditd          0:off   1:off   2:on    3:on    4:on    5:on    6:off\nblk-availability    0:off   1:on    2:on    3:on    4:on    5:on    6:off\ncassandra       0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncgconfig        0:off   1:off   2:off   3:off   4:off   5:off   6:off\ncgred           0:off   1:off   2:off   3:off   4:off   5:off   6:off\ncloud-config    0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-final     0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-init      0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-init-local    0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncrond           0:off   1:off   2:on    3:on    4:on    5:on    6:off\ndynomite        0:off   1:off   2:on    3:on    4:on    5:on    6:off\ndynomite-manager    0:off   1:off   2:on    3:on    4:on    5:on    6:off\nip6tables       0:off   1:off   2:on    3:on    4:on    5:on    6:off\niptables        0:off   1:off   2:on    3:on    4:on    5:on    6:off\nirqbalance      0:off   1:off   2:on    3:on    4:on    5:on    6:off\nlvm2-monitor    0:off   1:on    2:on    3:on    4:on    5:on    6:off\nmdmonitor       0:off   1:off   2:on    3:on    4:on    5:on    6:off\nmessagebus      0:off   1:off   2:on    3:on    4:on    5:on    6:off\nnetconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nnetfs           0:off   1:off   2:off   3:on    4:on    5:on    6:off\nnetwork         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nnfs             0:off   1:off   2:off   3:off   4:off   5:off   6:off\nnfslock         0:off   1:off   2:off   3:on    4:on    5:on    6:off\nntpd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nntpdate         0:off   1:off   2:on    3:on    4:on    5:on    6:off\npsacct          0:off   1:off   2:off   3:off   4:off   5:off   6:off\nquota_nld       0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrdisc           0:off   1:off   2:off   3:off   4:off   5:off   6:off\nredis_22122     0:off   1:off   2:on    3:on    4:on    5:on    6:off\nredis_6379      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrngd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nrpcbind         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nrpcgssd         0:off   1:off   2:off   3:on    4:on    5:on    6:off\nrpcsvcgssd      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrsyslog         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nsaslauthd       0:off   1:off   2:off   3:off   4:off   5:off   6:off\nsendmail        0:off   1:off   2:on    3:on    4:on    5:on    6:off\nsshd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nudev-post       0:off   1:on    2:on    3:on    4:on    5:on    6:off\n[ec2-user@ip-172-31-20-132 ~]$ \n\n\n\n\nNow we need Download and Install Cassandra. We also will need to setup the schemas with CQL and add some start up script as well. \n\nBEWARE this is a simpe imstalation in order to you TRY OUT Dynomite manager. This is a single cassandra. You should install a cassandra CLUSTER in your PROD env. \n\n\nDownload and Install Cassandra\n\n\ncd ~\nwget https://archive.apache.org/dist/cassandra/2.1.9/apache-cassandra-2.1.9-bin.tar.gz\ntar -xzvf apache-cassandra-2.1.9-bin.tar.gz\nrm -rf apache-cassandra-2.1.9-bin.tar.gz\n\n\n\n\nCreate the Dynomite Manager Schemas. First we need start cassandra.\n\n\n/home/ec2-user/apache-cassandra-2.1.9/\nbin/cassandra \n \n\n\n\n\nThem we needto creathe de CQL file.\n\n\ntouch dynomite-manager.cql\nvim dynomite-manager.cql\n\n\n\n\nWith this content: \n\n\n\nCREATE KEYSPACE dyno_bootstrap WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '3'}  AND durable_writes = true;\n\nCREATE TABLE dyno_bootstrap.tokens (\n    key text PRIMARY KEY,\n    \nId\n text,\n    \nappId\n text,\n    \navailabilityZone\n text,\n    datacenter text,\n    \nelasticIP\n text,\n    hostname text,\n    \ninstanceId\n text,\n    location text,\n    \ntoken\n text,\n    updatetime timeuuid\n) WITH COMPACT STORAGE\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = '{\nkeys\n:\nALL\n, \nrows_per_partition\n:\nNONE\n}'\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 256\n    AND read_repair_chance = 1.0\n    AND speculative_retry = 'NONE';\nCREATE INDEX tokens_appid_idx ON dyno_bootstrap.tokens (\nappId\n);\n\nCREATE TABLE dyno_bootstrap.locks (\n    key blob,\n    column1 text,\n    value blob,\n    PRIMARY KEY (key, column1)\n) WITH COMPACT STORAGE\n    AND CLUSTERING ORDER BY (column1 ASC)\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = '{\nkeys\n:\nALL\n, \nrows_per_partition\n:\nNONE\n}'\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 256\n    AND read_repair_chance = 1.0\n    AND speculative_retry = 'NONE';\n\n\n\n\n\nAnd them Import on CQL\n\n\n[ec2-user@ip-172-31-14-210 apache-cassandra-2.1.9]$ bin/cqlsh\nConnected to Test Cluster at 127.0.0.1:9042.\n[cqlsh 5.0.1 | Cassandra 2.1.14 | CQL spec 3.2.1 | Native protocol v3]\nUse HELP for help.\ncqlsh\n SOURCE 'dynomite-manager.cql'\ncqlsh\n \n\n\n\n\nOK. Now we need to create a startup script for Cassandra.\n\n\nsudo touch /etc/init.d/cassandra\nsudo vim /etc/init.d/cassandra\n\n\n\n\nWith this content:\n\n\n#!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: java\n\nstart() {\n   echo \nStarting cassandra...\n\n   export JAVA_HOME=/home/ec2-user/jdk1.8.0_45\n   export JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\n   export PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\n\n   cd /home/ec2-user/apache-cassandra-2.1.9\n   bin/cassandra start \n \n}\n\nstop() {\n   echo \nstop\n\n   PID=`ps aux | grep cassandra | grep -v grep | awk '{print $2}'`\n   if [[ \n !=  \n$PID\n ]]; then\n      echo \nkilling $PID\n\n      sudo kill -9 $PID\n   fi\n}\n\ncase \n$1\n in start)\n  start\n;;\n  stop)\n  stop\n;;\n*)\n\necho $\nUsage: $0 {start|stop}\n\nRETVAL=1\nesac\nexit 0\n\n\n\n\n\nWe need add permissions to execute and add to the boot up of the box.\n\n\nsudo chmod +x /etc/init.d/cassandra\nsudo chkconfig cassandra on\n\n\n\n\nNow we need move some files around and create some dirs. I'm doing this to make dynomite work with default settings. \n\nIf you want you can change the configs to point to other folders. \n\n\nsudo mkdir -p /logs/system/dynomite-manager/\nsudo mkdir -p /apps/dynomite/conf/\nsudo mkdir -p /apps/dynomite/bin/\nsudo mkdir -p /mnt/data/nfredis/\nsudo mkdir -p /logs/system/\nsudo mkdir -p /apps/nfredis/bin/\nsudo mkdir -p /logs/system/dynomite/\n\nsudo cp /home/ec2-user/dynomite/bin/kill_dynomite.sh /apps/dynomite/bin/\nsudo cp /home/ec2-user/dynomite/bin/launch_dynomite.sh /apps/dynomite/bin/\nsudo cp ~/dynomite/src/dynomite /apps/dynomite/bin/\nsudo cp ~/dynomite/src/*.* /apps/dynomite/bin/\nsudo cp ~/dynomite/conf/dynomite.pem /apps/dynomite/conf/dynomite.pem\nsudo cp ~/dynomite/conf/recon_key.pem /apps/dynomite/conf/\nsudo cp ~/dynomite/conf/recon_iv.pem /apps/dynomite/conf/\n\n#sudo cp /home/ec2-user/dynomite/bin/core_affinity.sh /apps/dynomite/bin/core_affinity.sh\nsudo cp /home/ec2-user/dynomite-manager-1/scripts/core_affinity-centos.sh /apps/dynomite/bin/core_affinity.sh\nsudo chmod +x /apps/dynomite/bin/core_affinity.sh\n\nsudo touch /apps/nfredis/bin/launch_nfredis.sh\nsudo vim /apps/nfredis/bin/launch_nfredis.sh\n#!/bin/bash\nsudo service redis_22122 start\n\nsudo chmod +x /apps/nfredis/bin/launch_nfredis.sh\nsudo touch /apps/nfredis/bin/kill_redis.sh\n\nsudo vim /apps/nfredis/bin/kill_redis.sh\n#!/bin/bash\nsudo service redis_22122 stop\n\nsudo chmod +x /apps/nfredis/bin/kill_redis.sh\n\nsudo mkdir -p /mnt/data/nfredis/\n\nsudo chmod -R 777 /logs/\nsudo chmod -R 777 /apps/\nsudo chmod -R 777 /mnt/\n\n\n\n\n\nAll Set. Now let's go to the AWS Ec2 console(https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:sort=desc:statusChecks) Right button of the mouse on the top of your instance and them Image menu -\n Create Image. \n\n\nImage Name: BASE_DYNOMITE_MANAGER \n\nImage Description: BASE_DYNOMITE_MANAGER \n\nHD: 20GB(Or anything you like it).\n\n\nCreate Launch Config\n\n\nGo to the Launch Configuration(https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#LaunchConfigurations:) and create a LC: \n\n\nSelect My AMIs and them: BASE_DYNOMITE_MANAGER \n\nSelect the Instance Type: m4.large(Or anything you like it). \n\nAs Launch Configuration name: lc_dynomite_manager \n\nIAM role: dynomite \n\nMonitoring: Mark - Enable CloudWatch detailed monitoring \n\nStorage: 20GB(Or anything you like it) \n\nSecurity Group: Select - sg_asg_dynomite_florida \n\nFor PEM file pick anyone you want it.\n\n\nCreate ASG\n\n\nNow is the time to create a Autoscaling group. Goto ASG(https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#AutoScalingGroups:view=details) and create a new one: \n\nSelect the Launch Configuration: lc_dynomite_manager\n\nGroup name: asg_dynomite \n\nGroup size: 3\n\nVPC: Use the Default(Or anyone you like it)\n\nFor TAGS: key: name value: asg_dynomite\n\n\nAll Set! Now we can ssh in one of the 3 boxes to play with the REST operations!\n\n\nREST endpoints\n\n\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/takesnapshot\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/start\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/stop\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/cluster_describe\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/startstorageprocess\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/stopstorageprocess\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/backup\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/restore\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/get_seeds\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/status\n\n\n\n\nMore details here: https://github.com/Netflix/dynomite-manager/wiki/REST-API\n\n\nWe also can take a look at the dynomite-manager log using the bash alias dmlog.\n\n\n[ec2-user@ip-172-31-20-132 bin]$ which dmlog\nalias dmlog='tail -f -n 2000 /logs/system/dynomite-manager/dynomite-manager.log'\n    /usr/bin/tail\n[ec2-user@ip-172-31-20-132 bin]$ sudo rm -rf /logs/system/dynomite-manager/dynomite-manager.log\n[ec2-user@ip-172-31-20-132 bin]$ \n[ec2-user@ip-172-31-20-132 bin]$ \n[ec2-user@ip-172-31-20-132 bin]$ cls\n\n[ec2-user@ip-172-31-20-132 bin]$ sudo /etc/init.d/dynomite-manager start\nStarting Dynomite Manager...\n[ec2-user@ip-172-31-20-132 bin]$ dmlog \nInferred project: dynomite-manager, version: 0.1.0-SNAPSHOT\nThe testJar task is deprecated.  Please place common test harness code in its own project and publish separately.\nPublication nebula not found in project :.\n[buildinfo] Not using buildInfo properties file for this build.\nPublication named 'nebula' does not exist for project ':' in task ':artifactoryPublish'.\n:dynomitemanager:compileJavawarning: [options] bootstrap class path not set in conjunction with -source 1.7\n1 warning\n\n:dynomitemanager:processResources UP-TO-DATE\n:dynomitemanager:classes\n:dynomitemanager:writeManifestProperties\n:dynomitemanager:jar\n:dynomitemanager-web:compileJava UP-TO-DATE\n:dynomitemanager-web:processResources UP-TO-DATE\n:dynomitemanager-web:classes UP-TO-DATE\n:dynomitemanager-web:jettyRunSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/root/.gradle/wrapper/dists/gradle-2.12-bin/avhnk0p45wmm16bas931at19r/gradle-2.12/lib/gradle-core-2.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/root/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.2/7539c264413b9b1ff9841cd00058c974b7cd1ec9/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n\n2016-06-30 03:01:35 INFO  InjectedWebListener:112 - **Binding OSS Config classes.\n2016-06-30 03:01:36 WARN  URLConfigurationSource:120 - No URLs will be polled as dynamic configuration sources.\n2016-06-30 03:01:36 INFO  URLConfigurationSource:121 - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.\n2016-06-30 03:01:36 INFO  DynamicPropertyFactory:281 - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@39785b39\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/placement/availability-zone returns: us-west-2a\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/public-hostname returns: ec2-52-41-84-223.us-west-2.compute.amazonaws.com\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/public-ipv4 returns: 52.41.84.223\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/instance-id returns: i-e084504f\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/instance-type returns: m4.large\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/ returns: 02:af:8a:49:12:49/\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/ returns: 02:af:8a:49:12:49/\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/02:af:8a:49:12:49/vpc-id returns: vpc-aeeb50cb\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:245 - vpc id for running instance: vpc-aeeb50cb\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:278 - Setting up Environmental Variables\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:286 - REGION set to us-west-2, ASG Name set to asg_dynomite1\n2016-06-30 03:01:36 INFO  PropertiesConfigSource:83 - No Dynomitemanager.properties. Ignore!\n2016-06-30 03:01:36 INFO  PropertiesConfigSource:83 - No Dynomitemanager.properties. Ignore!\n2016-06-30 03:01:37 INFO  SimpleThreadPool:267 - Job execution threads will use class loader of thread: main\n2016-06-30 03:01:37 INFO  SchedulerSignalerImpl:60 - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\n2016-06-30 03:01:37 INFO  QuartzScheduler:220 - Quartz Scheduler v.1.7.3 created.\n2016-06-30 03:01:37 INFO  RAMJobStore:139 - RAMJobStore initialized.\n2016-06-30 03:01:37 INFO  StdSchedulerFactory:1240 - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'\n2016-06-30 03:01:37 INFO  StdSchedulerFactory:1244 - Quartz scheduler version: 1.7.3\n2016-06-30 03:01:37 INFO  QuartzScheduler:2075 - JobFactory set to: com.netflix.dynomitemanager.sidecore.scheduler.GuiceJobFactory@3875b3c9\n2016-06-30 03:01:37 INFO  InstanceDataDAOCassandra:351 - BOOT_CLUSTER = cass_dyno, KS_NAME = dyno_bootstrap\n2016-06-30 03:01:37 INFO  CountingConnectionPoolMonitor:194 - AddHost: 127.0.0.1\n2016-06-30 03:01:37 INFO  ConnectionPoolMBeanManager:53 - Registering mbean: com.netflix.MonitoredResources:type=ASTYANAX,name=MyConnectionPool,ServiceType=connectionpool\n2016-06-30 03:01:38 INFO  UpdateChecker:86 - New update(s) found: 1.8.5 [http://www.terracotta.org/kit/reflector?kitID=default\npageID=QuartzChangeLog]\n2016-06-30 03:01:38 INFO  InstanceIdentity:136 - My token: 3530913378\n2016-06-30 03:01:38 INFO  FloridaServer:79 - Initializing Florida Server now ...\n2016-06-30 03:01:38 INFO  AWSMembership:265 - Fetch current permissions for vpc env of running instance\n2016-06-30 03:01:38 INFO  FloridaServer:103 - Running TuneTask and updating configuration.\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:136 - dyn_o_mite:\n  dyn_listen: 0.0.0.0:8101\n  data_store: 0\n  listen: 0.0.0.0:8102\n  dyn_seed_provider: florida_provider\n  servers:\n  - 127.0.0.1:22122:1\n  tokens: '3530913378'\n  auto_eject_hosts: true\n  rack: asg_dynomite1\n  distribution: vnode\n  gos_interval: 10000\n  hash: murmur\n  preconnect: true\n  server_retry_timeout: 30000\n  timeout: 5000\n  secure_server_option: datacenter\n  datacenter: us-west-2\n  read_consistency: DC_ONE\n  write_consistency: DC_ONE\n  pem_key_file: /apps/dynomite/conf/dynomite.pem\n\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:250 - totalMem:8178632 Setting Redis storage max mem to 6081480\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:164 - Updating Redis conf: /apps/nfredis/conf/redis.conf\n2016-06-30 03:01:38 INFO  FloridaServer:112 - Restore is disabled.\n2016-06-30 03:01:38 INFO  FloridaServer:121 - Cold bootstraping, launching dynomite and storage process.\n2016-06-30 03:01:38 INFO  FloridaProcessManager:74 - Starting dynomite server joinRing:true\n2016-06-30 03:01:43 ERROR FloridaProcessManager:99 - Unable to start Dynomite server. Error code: 1\n2016-06-30 03:01:43 INFO  FloridaProcessManager:124 - std_out: MBUF_SIZE=16384\nALLOC_MSGS=200000\n\ndynomite pid: \ntaskset: invalid PID argument: '2,5,6'\nredis pid: 8124\ntaskset: failed to set pid 8124's affinity: Invalid argument\npid 8124's current affinity list: 0,1\n\n2016-06-30 03:01:43 INFO  FloridaProcessManager:125 - std_err: \n2016-06-30 03:01:44 INFO  RedisStorageProxy:351 - Checking if Redis needs to be resetted to master\n2016-06-30 03:01:44 INFO  ProxyAndStorageResetTask:74 - Checking Dynomite's status\n2016-06-30 03:01:44 INFO  ProxyAndStorageResetTask:94 - Dynomite is up and running\n2016-06-30 03:01:44 INFO  FloridaServer:142 - Starting task scheduler\n2016-06-30 03:01:44 INFO  QuartzScheduler:472 - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.\n2016-06-30 03:01:44 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-30 03:01:44 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=false, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsed to check (micros): 40004\n2016-06-30 03:01:44 INFO  AWSMembership:265 - Fetch current permissions for vpc env of running instance\n\n\n\n\n\nTroubleshooting:\n\n\nMake sure you have all this OS_ENV vars:\n\n\nexport ASG_NAME=\nasg_dynomite\n\nexport AUTO_SCALE_GROUP=\nasg_dynomite\n\nexport EC2_REGION=\nus-west-2\n\nexport NETFLIX_APP=\nsg_asg_dynomite_florida\n\n\n\n\n\nget_seeds\n\n\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/get_seeds\n\n\n016-06-23 23:44:32 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-23 23:44:32 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=true, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsted to check (micros): 12779\n2016-06-23 23:44:43 ERROR DynomiteAdmin:194 - Cannot find the Seeds\n2016-06-23 23:44:47 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-23 23:44:47 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=true, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsted to check (micros): 7216\n\n\n\n\n\n\nMake sure the ASG ash 3 instances\n\n\nMake sure you have the right dynomite.yml config in place\n\n\n\n\ns3_backup\n\n\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/s3restore\n\n\nON S3: 1383429731\nRestore: 1286668800000\n\n\n2016-06-24 02:26:56 INFO  FloridaProcessManager:168 - Dynomite server has been stopped\n2016-06-24 02:26:56 INFO  StorageProcessManager:126 - Stopping Storage process ....\n2016-06-24 02:26:59 WARN  JedisUtils:112 - All retries to connect to host:127.0.0.1 port:8102 failed.\n2016-06-24 02:26:59 INFO  JedisUtils:54 - Unable to connect\n2016-06-24 02:26:59 ERROR BoundedExponentialRetryCallable:64 - Retry #1 for: Failed Jedis connect host:127.0.0.1 port:22122 failed.\n2016-06-24 02:27:01 INFO  StorageProcessManager:148 - Storage process has been stopped\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:190 - Date to restore to: 20101010\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:125 - Restoring data from S3.\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:137 - S3 Bucket Name: dynomite-backup\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:138 - Key in Bucket: backup/us-west-2/asg_dynomite/1383429731/1286668800000\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:166 - AmazonServiceException; request made it to Amazon S3, but was rejected with an error \n2016-06-24 02:27:02 ERROR RestoreFromS3Task:168 - Error Message:    The specified key does not exist. (Service: Amazon S3; Status Code: 404; Error Code: NoSuchKey; Request ID: DA23FBFCA68F27FE)\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:169 - HTTP Status Code: 404\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:170 - AWS Error Code:   NoSuchKey\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:171 - Error Type:       Client\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:172 - Request ID:       DA23FBFCA68F27FE\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:111 - S3 Restore not successful: Starting storage process without loading data.\n\n\n\n\n\n\nBEWARE of the DATE diff you need have file based on time diff. Check RestoreFromS3Task.java\n\n\nNeed have permissions on: /mnt/data/\n\n\n\n\nposition must be \n= 0\n\n\n2016-06-25 01:18:09 ERROR RetryableCallable:72 - Retry #1 for: position must be \n= 0\n2016-06-25 01:18:09 ERROR RetryableCallable:75 - Exception --\n java.lang.IllegalArgumentException: position must be \n= 0\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\n    at com.netflix.dynomitemanager.sidecore.utils.TokenManager.initialToken(TokenManager.java:47)\n    at com.netflix.dynomitemanager.sidecore.utils.TokenManager.createToken(TokenManager.java:75)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$GetNewToken.retriableCall(InstanceIdentity.java:245)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$GetNewToken.retriableCall(InstanceIdentity.java:220)\n    at com.netflix.dynomitemanager.sidecore.utils.RetryableCallable.call(RetryableCallable.java:59)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity.init(InstanceIdentity.java:134)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity.\ninit\n(InstanceIdentity.java:86)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$$FastClassByGuice$$17e6ff76.newInstance(\ngenerated\n)\n    at com.google.inject.internal.cglib.reflect.$FastConstructor.newInstance(FastConstructor.java:40)\n    at com.google.inject.internal.DefaultConstructionProxyFactory$1.newInstance(DefaultConstructionProxyFactory.java:60)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:85)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:254)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1031)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.Scopes$1$1.get(Scopes.java:65)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:40)\n    at com.google.inject.internal.SingleParameterInjector.inject(SingleParameterInjector.java:38)\n    at com.google.inject.internal.SingleParameterInjector.getAll(SingleParameterInjector.java:62)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:84)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:254)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1031)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.Scopes$1$1.get(Scopes.java:65)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:40)\n    at com.google.inject.internal.InjectorImpl$4$1.call(InjectorImpl.java:978)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1024)\n    at com.google.inject.internal.InjectorImpl$4.get(InjectorImpl.java:974)\n    at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1013)\n    at com.netflix.dynomitemanager.defaultimpl.InjectedWebListener.getInjector(InjectedWebListener.java:83)\n    at com.google.inject.servlet.GuiceServletContextListener.contextInitialized(GuiceServletContextListener.java:45)\n    at org.mortbay.jetty.handler.ContextHandler.startContext(ContextHandler.java:548)\n    at org.mortbay.jetty.servlet.Context.startContext(Context.java:136)\n    at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1272)\n    at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:517)\n    at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:489)\n    at org.gradle.api.plugins.jetty.internal.JettyPluginWebAppContext.doStart(JettyPluginWebAppContext.java:112)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)\n    at org.mortbay.jetty.Server.doStart(Server.java:224)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.gradle.api.plugins.jetty.internal.Jetty6PluginServer.start(Jetty6PluginServer.java:111)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJettyInternal(AbstractJettyRunTask.java:238)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJetty(AbstractJettyRunTask.java:191)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.start(AbstractJettyRunTask.java:162)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.doExecute(AnnotationProcessingTaskFactory.java:227)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:220)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:209)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:585)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:568)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)\n    at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)\n    at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\n    at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)\n    at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50)\n    at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:25)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:110)\n    at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23)\n    at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43)\n    at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30)\n    at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:154)\n    at org.gradle.internal.Factories$1.create(Factories.java:22)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:52)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:151)\n    at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:32)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:99)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:93)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:62)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:93)\n    at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:82)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.run(InProcessBuildActionExecuter.java:94)\n    at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:43)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:45)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28)\n    at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43)\n    at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:169)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:33)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:22)\n    at org.gradle.launcher.Main.doAction(Main.java:33)\n    at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35)\n    at org.gradle.launcher.GradleMain.main(GradleMain.java:23)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30)\n    at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129)\n    at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61)\n\n\n\n\n\nThis means you are not running Dynomite Manager whithin an ASG(Auto Scalling Group), Once you do it, shoudl fix the problem.\n\n\nUnable to get group-id or group-name\n\n\n2016-06-30 02:36:16 ERROR AWSMembership:191 - unable to get group-id for group-name=asg_dynomite1 vpc-id=vpc-aeeb50cb\n2016-06-30 02:36:16 ERROR Task:99 - Couldnt execute the task because of The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: b211f8ad-150d-4148-9d14-9b08fcce93a5)\ncom.amazonaws.AmazonServiceException: The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: b211f8ad-150d-4148-9d14-9b08fcce93a5)\n    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1383)\n    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:902)\n    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:607)\n    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:376)\n    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:338)\n    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:287)\n    at com.amazonaws.services.ec2.AmazonEC2Client.invoke(AmazonEC2Client.java:11128)\n    at com.amazonaws.services.ec2.AmazonEC2Client.authorizeSecurityGroupIngress(AmazonEC2Client.java:1019)\n    at com.netflix.dynomitemanager.sidecore.aws.AWSMembership.addACL(AWSMembership.java:153)\n    at com.netflix.dynomitemanager.sidecore.aws.UpdateSecuritySettings.execute(UpdateSecuritySettings.java:70)\n    at com.netflix.dynomitemanager.sidecore.scheduler.Task.execute(Task.java:93)\n    at org.quartz.core.JobRunShell.run(JobRunShell.java:199)\n    at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:546)\n\n\n2016-06-30 02:44:10 INFO  FloridaServer:79 - Initializing Florida Server now ...\n2016-06-30 02:44:10 INFO  AWSMembership:269 - Fetch current permissions for vpc env of running instance\n2016-06-30 02:44:10 ERROR AWSMembership:191 - unable to get group-id for group-name=asg_dynomite vpc-id=vpc-aeeb50cb\n2016-06-30 02:44:10 ERROR Task:99 - Couldnt execute the task because of The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: 85d82dba-e3b2-4e30-9087-00a84371ed69)\ncom.amazonaws.AmazonServiceException: The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: 85d82dba-e3b2-4e30-9087-00a84371ed69)\n    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1383)\n    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:902)\n    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:607)\n    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:376)\n    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:338)\n    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:287)\n    at com.amazonaws.services.ec2.AmazonEC2Client.invoke(AmazonEC2Client.java:11128)\n    at com.amazonaws.services.ec2.AmazonEC2Client.authorizeSecurityGroupIngress(AmazonEC2Client.java:1019)\n    at com.netflix.dynomitemanager.sidecore.aws.AWSMembership.addACL(AWSMembership.java:153)\n    at com.netflix.dynomitemanager.sidecore.aws.UpdateSecuritySettings.execute(UpdateSecuritySettings.java:70)\n    at com.netflix.dynomitemanager.sidecore.scheduler.Task.execute(Task.java:93)\n    at com.netflix.dynomitemanager.sidecore.scheduler.TaskScheduler.runTaskNow(TaskScheduler.java:98)\n    at com.netflix.dynomitemanager.FloridaServer.initialize(FloridaServer.java:84)\n    at com.netflix.dynomitemanager.defaultimpl.InjectedWebListener.getInjector(InjectedWebListener.java:83)\n    at com.google.inject.servlet.GuiceServletContextListener.contextInitialized(GuiceServletContextListener.java:45)\n    at org.mortbay.jetty.handler.ContextHandler.startContext(ContextHandler.java:548)\n    at org.mortbay.jetty.servlet.Context.startContext(Context.java:136)\n    at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1272)\n    at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:517)\n    at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:489)\n    at org.gradle.api.plugins.jetty.internal.JettyPluginWebAppContext.doStart(JettyPluginWebAppContext.java:112)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)\n    at org.mortbay.jetty.Server.doStart(Server.java:224)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.gradle.api.plugins.jetty.internal.Jetty6PluginServer.start(Jetty6PluginServer.java:111)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJettyInternal(AbstractJettyRunTask.java:238)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJetty(AbstractJettyRunTask.java:191)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.start(AbstractJettyRunTask.java:162)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.doExecute(AnnotationProcessingTaskFactory.java:227)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:220)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:209)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:585)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:568)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)\n    at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)\n    at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\n    at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)\n    at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50)\n    at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:25)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:110)\n    at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23)\n    at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43)\n    at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30)\n    at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:154)\n    at org.gradle.internal.Factories$1.create(Factories.java:22)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:52)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:151)\n    at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:32)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:99)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:93)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:62)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:93)\n    at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:82)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.run(InProcessBuildActionExecuter.java:94)\n    at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:43)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:45)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28)\n    at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43)\n    at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:169)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:33)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:22)\n    at org.gradle.launcher.Main.doAction(Main.java:33)\n    at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35)\n    at org.gradle.launcher.GradleMain.main(GradleMain.java:23)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30)\n    at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129)\n    at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61)\n\n\n\n\nMake sure you have the OS env var called NETFLIX_APP pointing to the right Security Group name. \n\n\nMore on Redis Persistence check\n\n\nLook for the BGREWRITEAOF Command\nhttp://redis.io/topics/persistence\n\n\n\n\nSome important Classes for Configs:\n\n\nInjectedWebListener\nDynomitemanagerConfiguration\nDynomiteAdmin\nFloridaProcessManager\nRedisStorageProxy\nSnapshotBackup\nInstanceProfileCredentialsProvider\nEC2MetadataClient", 
            "title": "Step by step installation"
        }, 
        {
            "location": "/Step-by-step-installation/#aws-deployment", 
            "text": "Author:  Diego Pacheco", 
            "title": "AWS Deployment"
        }, 
        {
            "location": "/Step-by-step-installation/#install-cassandra-for-token-management", 
            "text": "", 
            "title": "Install Cassandra for Token Management"
        }, 
        {
            "location": "/Step-by-step-installation/#install-java-8", 
            "text": "# Remove java 7\nsudo yum remove -y java\n\n# Install basic packages\nsudo yum install -y git\n\n# Download and install java 8\nwget --no-cookies --no-check-certificate --header  Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie   http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.tar.gz \ntar -xzvf jdk-8u45-linux-x64.tar.gz\nrm -rf jdk-8u45-linux-x64.tar.gz\n\n# Configure JAVA_HOME\nsudo vim ~/.bashrc  alias cls='clear'\n\nexport JAVA_HOME=~/jdk1.8.0_45\nexport JRE_HOME=~/jdk1.8.0_45/jre\nexport PATH=$PATH:~/jdk1.8.0_45/bin:/~/jdk1.8.0_45/jre/bin  source ~/.bashrc \njava -version", 
            "title": "Install java 8"
        }, 
        {
            "location": "/Step-by-step-installation/#cassandra-2x", 
            "text": "wget https://archive.apache.org/dist/cassandra/2.1.9/apache-cassandra-2.1.9-bin.tar.gz\ntar -xzvf apache-cassandra-2.1.9-bin.tar.gz\nrm -rf apache-cassandra-2.1.9-bin.tar.gz", 
            "title": "Cassandra 2.x"
        }, 
        {
            "location": "/Step-by-step-installation/#configure-the-cassandra-cluster", 
            "text": "# your_server_ip - copy the IP\nhostname -i\nvim ~/apache-cassandra-2.1.9/conf/cassandra.yaml  cluster_name: 'Test Cluster'\nlisten_address: your_server_ip\nrpc_address: your_server_ip\nseed_provider:\n  - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n    parameters:\n         - seeds:  ip1,ip2,...ipN \nendpoint_snitch: GossipingPropertyFileSnitch", 
            "title": "Configure the Cassandra Cluster"
        }, 
        {
            "location": "/Step-by-step-installation/#start-up-the-cassandra-cluster", 
            "text": "# on each Cassandra node... \ncd ~/apache-cassandra-2.1.9\nbin/cassandra start", 
            "title": "Start up the Cassandra cluster"
        }, 
        {
            "location": "/Step-by-step-installation/#open-ec2-security-group-ports", 
            "text": "7000\n9160\n9042", 
            "title": "Open EC2 Security Group ports"
        }, 
        {
            "location": "/Step-by-step-installation/#test-data-replication-with-cqlsh", 
            "text": "# Connect to any node - you can run: hostname -i to get the IP\napache-cassandra-2.1.9/bin/cqlsh IP  CREATE KEYSPACE CLUSTER_TEST WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 }; \nUSE CLUSTER_TEST;\nCREATE TABLE TEST ( key text PRIMARY KEY, value text);\nINSERT INTO TEST (key,value) VALUES ('1', 'works');\nSELECT * from TEST;  # Connect to any other node - you can run: hostname -i to get the IP - check for data replication\napache-cassandra-2.1.9/bin/cqlsh IP\nUSE CLUSTER_TEST;\nSELECT * from TEST;", 
            "title": "Test data replication with cqlsh"
        }, 
        {
            "location": "/Step-by-step-installation/#create-a-aws-role-called-dynomite", 
            "text": "Goto Identity and Access Management(https://console.aws.amazon.com/iam/home?region=us-west-2#roles) at Roles.  \nCreate a new role called: dynomite and add the policies:   \n    AmazonEC2FullAccess\n    AmazonS3FullAccess\n    IAMFullAccess", 
            "title": "Create a AWS Role called: dynomite"
        }, 
        {
            "location": "/Step-by-step-installation/#create-s3-bucket", 
            "text": "Goto S3(https://console.aws.amazon.com/s3/home?region=us-west-2#) and create bucket called: dynomite-backup.\nGoto Properties-  Permissions and them add: Any Authenticated AWS User (List, Upload/Delete/View/Edit).", 
            "title": "Create S3 bucket"
        }, 
        {
            "location": "/Step-by-step-installation/#setup-dynomite-and-dynomite-manager-build-an-ami", 
            "text": "2.1. Create a Amazon Linux AMI Box  \n2.1.1. Select The Instance type: m4.large Or anything you like it.  \n2.1.2. Configure the Instance Details: IAM Roles: IAM role  \n2.1.3. Configure the Instance Details: Monitoring - Mark Enable CloudWatch detailed monitoring  \n2.1.4. Add Storage: 20Gb storare Or anything you like it.   \n2.1.5. Tag Instance: dynomite_dynomitemanager  \n2.1.6. Configure Security Group: sg_asg_dynomite_florida with rules:  \nEnable TCP:   \n   22\n   8080\n   8000 - 8100 (for debug)\n   8101 - 8102(dynomite) \n   7000 (cassandra) \n   9160 (cassandra) \n   9042 (cassandra)      This could vary depending of your VPC config because  \nyou might need add several rules dependeing how my ips you need to allow. But this are the ports you need be enable.   2.1.7. Pick whatever PEM file do you want. Finish the Box creation and SSH to the box.  \n3. Installing Dynomite, Redis, Dynomite-Manager and Cassandra  Let's update the OS first.  sudo yum update -y  Let's setup Java JDK 8(Needed by Dynomite Manager).  sudo yum remove java -y\nsudo wget --no-cookies --no-check-certificate --header  Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie   http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.tar.gz \ntar -xzvf jdk-8u45-linux-x64.tar.gz\nrm -rf jdk-8u45-linux-x64.tar.gz  We also need export JAVA OS env vars. Let's edit /etc/profile and add:  export JAVA_HOME=/home/ec2-user/jdk1.8.0_45\nexport JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\nexport PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\n\nalias cls=clear\nalias dlog='tail -f -n 2000  /logs/system/dynomite/dynomite.log'\nalias dmlog='tail -f -n 2000 /logs/system/dynomite-manager/dynomite-manager.log'\nalias rlog='tail -f -n 2000 /var/log/redis_22122.log'\nalias clog='tail -f -n 2000 /home/ec2-user/apache-cassandra-2.1.9/logs/system.log'\nalias dgrep='ps aux | grep dynomite'\nalias rcli='redis-cli -p 8102'\nalias dconf='cat /apps/dynomite/conf/dynomite.yml'  As you can see we also added some bash alias to make your life easier. :-)     We need to source this file in order to have the variables and alias available, do:  source /etc/profile  Let's move to dynomite now. Let's Download and Build it.  sudo yum install git -y\ngit clone https://github.com/Netflix/dynomite.git\ncd dynomite\nsudo yum install -y autoconf automake\nsudo yum install -y libtool\nsudo yum install -y openssl-devel\nautoreconf -fvi\n./configure --enable-debug=log\nmake  In order to test Dynomite Installation just run:  src/dynomite -h  You should see something like:  [ec2-user@ip-172-31-14-210 dynomite]$ src/dynomite -h\nThis is dynomite-alloc_msg_leak-130-g68683f0\n\nUsage: dynomite [-?hVdDt] [-v verbosity level] [-o output file]\n                  [-c conf file] [-s stats port] [-a stats addr]\n                  [-i stats interval] [-p pid file] [-m mbuf size]\n                  [-M max alloc messages]\n\nOptions:\n  -h, --help             : this help\n  -V, --version          : show version and exit\n  -t, --test-conf        : test configuration for syntax errors and exit\n  -g, --gossip           : enable gossip (default: disable)\n  -d, --daemonize        : run as a daemon\n  -D, --describe-stats   : print stats description and exit\n  -v, --verbosity=N            : set logging level (default: 5, min: 0, max: 11)\n  -o, --output=S               : set logging file (default: stderr)\n  -c, --conf-file=S            : set configuration file (default: conf/dynomite.yml)\n  -s, --stats-port=N           : set stats monitoring port (default: 22222)\n  -a, --stats-addr=S           : set stats monitoring ip (default: 0.0.0.0)\n  -i, --stats-interval=N       : set stats aggregation interval in msec (default: 30000 msec)\n  -p, --pid-file=S             : set pid file (default: off)\n  -m, --mbuf-size=N            : set size of mbuf chunk in bytes (default: 16384 bytes)\n  -M, --max-msgs=N             : set max number of messages to allocate (default: 200000)\n  -x, --admin-operation=N      : set size of admin operation (default: 0)  Adding the Dynomite config.   sudo mkdir -p /apps/dynomite/conf/\nsudo vim /apps/dynomite/conf/dynomite.yml  With the content:  dyn_o_mite:\n  dyn_listen: 0.0.0.0:8101\n  data_store: 0\n  listen: 0.0.0.0:8102\n  dyn_seed_provider: florida_provider\n  servers:\n    - 127.0.0.1:22122:1\n  tokens: '1383429731'\n  auto_eject_hosts: true\n  rack: null\n  distribution: vnode\n  gos_interval: 10000\n  hash: murmur\n  preconnect: true\n  server_retry_timeout: 30000\n  timeout: 5000\n  secure_server_option: datacenter\n  datacenter: us-west-2\n  read_consistency: DC_ONE\n  write_consistency: DC_ONE\n  pem_key_file: /apps/dynomite/conf/dynomite.pem  Let's create a startup script for Dynomite.  sudo touch /etc/init.d/dynomite\nsudo vim /etc/init.d/dynomite  With the content:  #!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: dynomite\n\nstart() {\n   echo  starting dynomite...  \n   cd /apps/dynomite/\n   sudo bin/dynomite -d -c /apps/dynomite/conf/dynomite.yml -m16384 -M200000 --output=/logs/system/dynomite/dynomite.log  \n}\n\nstop() {\n   echo  stop \n   PID=`pgrep dynomite`\n   if [[   !=   $PID  ]]; then\n      echo  killing $PID \n      kill -9 $PID\n   fi\n}\n\ncase  $1  in start)\n  start\n;;\n  stop)\n  stop\n;;\n*)\n\necho $ Usage: $0 {start|stop} \nRETVAL=1\nesac\nexit 0  Now we need add permissions to execute and put it on the startup of the box.  sudo chmod +x /etc/init.d/dynomite\nsudo chkconfig dynomite off  OK. Next step is install Redis 3.X.  cd ..\nsudo yum install -y gcc*\nsudo yum install -y tcl\nwget http://download.redis.io/releases/redis-3.0.4.tar.gz\ntar xzf redis-3.0.4.tar.gz\ncd redis-3.0.4\ncd deps ; make hiredis jemalloc linenoise lua ; cd ..\nmake\nmake test\nsudo make install\ncd utils ; sudo chmod +x install_server.sh ; sudo ./install_server.sh  The last command will start the redis installer you will need anwser the questions as I did it here:  Welcome to the redis service installer\nThis script will help you easily set up a running redis server\n\nPlease select the redis port for this instance: [6379] 22122\nPlease select the redis config file name [/etc/redis/22122.conf] /apps/nfredis/conf/redis.conf\nPlease select the redis log file name [/var/log/redis_22122.log] /var/log/redis_22122.log\nPlease select the data directory for this instance [/var/lib/redis/22122] /mnt/data/nfredis/\nPlease select the redis executable path [] /usr/local/bin/redis-server\nSelected config:\nPort           : 22122\nConfig file    : /apps/nfredis/conf/redis.conf\nLog file       : /var/log/redis_22122.log\nData dir       : /mnt/data/nfredis/\nExecutable     : /usr/local/bin/redis-server\nCli Executable : /usr/local/bin/redis-cli\nIs this ok? Then press ENTER to go on or Ctrl-C to abort.\nCopied /tmp/22122.conf =  /etc/init.d/redis_22122\nInstalling service...\nSuccessfully added to chkconfig!\nSuccessfully added to runlevels 345!\nStarting Redis server...\nInstallation successful!  After the installation we should test your Redis installation doing this:  cd ~\nrm -rf redis-3.0.4.tar.gz\n\n[ec2-user@ip-172-31-14-210 utils]$ redis-cli\nCould not connect to Redis at 127.0.0.1:6379: Connection refused\nnot connected  \n[ec2-user@ip-172-31-14-210 utils]$ redis-cli -p 22122\n127.0.0.1:22122  set k1 redis\nOK\n127.0.0.1:22122  get k1 redis \n127.0.0.1:22122    Since Redis is working we can test Dynomite as Well. Dynomite is RESP compatible let's test ddynomite using the standard  redis client. Redis is on the port 21222 and dynomite on 8102.  [ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122  set k1 redis\nOK\n127.0.0.1:22122  get k1 redis \n127.0.0.1:22122  \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122  get k1 redis \n127.0.0.1:22122  \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 8102\n127.0.0.1:8102  get k1 redis \n127.0.0.1:8102  set k1 dynomite\nOK\n127.0.0.1:8102  get k1 dynomite \n127.0.0.1:8102  \n[ec2-user@ip-172-31-20-132 ~]$ redis-cli -p 22122\n127.0.0.1:22122  get k1 dynomite \n127.0.0.1:22122    We also can check the log using our bash alias dlog.       #                                      m                        \n  mmm#  m   m  mmmm    mmm   mmmmm  mmm    mm#mm   mmm                \n #   #  \\m m/  #   #  #   #  # # #    #      #    #   #               \n #   #   #m#   #   #  #   #  # # #    #      #    #''''               \n \\#m##   \\#    #   #   #m#   # # #  mm#mm    mm    #mm                \n         m/                                \n[2016-06-25 18:59:25.557] stats_listen:1294 m 5 listening on '0.0.0.0:22222'\n[2016-06-25 18:59:25.557] entropy_key_iv_load:365 Key File name: conf/recon_key.pem - IV File name: conf/recon_iv.pem\n[2016-06-25 18:59:25.558] entropy_key_iv_load:420 key loaded: 0123456789012345\n[2016-06-25 18:59:25.558] entropy_key_iv_load:428 iv loaded: 0123456789012345\n[2016-06-25 18:59:25.558] entropy_listen:329 anti-entropy m 9 listening on '127.0.0.1:8105'\n[2016-06-25 18:59:25.558] conn_connect:525 connected to '127.0.0.1:22122:1' on p 12\n[2016-06-25 18:59:25.558] proxy_init:124 p 13 listening on '0.0.0.0:8102' in redis pool 'dyn_o_mite'\n[2016-06-25 18:59:25.558] dnode_init:108 dyn: p 14 listening on '0.0.0.0:8101' in redis pool 'dyn_o_mite' with 14615920 servers\n[2016-06-25 18:59:25.558] preselect_remote_rack_for_replication:1803 my rack index 0\n[2016-06-25 18:59:28.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33040'\n[2016-06-25 18:59:28.756] _msg_get:286 alloc_msg_count: 1 caller: req_get conn: CLIENT sd: 15\n[2016-06-25 18:59:28.756] _msg_get:286 alloc_msg_count: 2 caller: rsp_get conn: SERVER sd: 12\n[2016-06-25 18:59:28.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:28.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 18:59:43.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33046'\n[2016-06-25 18:59:43.757] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:43.757] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 18:59:58.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33054'\n[2016-06-25 18:59:58.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 18:59:58.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:03.515] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33058'\n[2016-06-25 19:00:13.756] proxy_accept:220 accepted CLIENT 16 on PROXY 13 from '127.0.0.1:33062'\n[2016-06-25 19:00:13.756] core_close_log:307 close CLIENT 16 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:13.756] client_unref_internal_try_put:124 unref conn 0xdf9bb0 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:18.768] conn_recv_data:614 recv on sd 15 eof rb 77 sb 30\n[2016-06-25 19:00:18.768] core_close_log:307 close CLIENT 15 '127.0.0.1:33058' on event 00FF eof 1 done 1 rb 77 sb 30  \n[2016-06-25 19:00:18.768] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:28.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33068'\n[2016-06-25 19:00:28.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:28.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'\n[2016-06-25 19:00:43.756] proxy_accept:220 accepted CLIENT 15 on PROXY 13 from '127.0.0.1:33076'\n[2016-06-25 19:00:43.756] core_close_log:307 close CLIENT 15 'unknown' on event FF00FF eof 0 done 0 rb 14 sb 7: Connection reset by peer\n[2016-06-25 19:00:43.756] client_unref_internal_try_put:124 unref conn 0xdf5490 owner 0xde90a0 from pool 'dyn_o_mite'  We can check Redis log too. With the bash alias rlog.  [ec2-user@ip-172-31-31-8 dynomite-manager-1]$ rlog \n19899:M 29 Jun 02:27:47.411 * Increased maximum number of open files to 10032 (it was originally set to 1024).\n                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.0.4 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 22122\n |    `-._   `._    /     _.-'    |     PID: 19899\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n19899:M 29 Jun 02:27:47.411 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n19899:M 29 Jun 02:27:47.411 # Server started, Redis version 3.0.4\n19899:M 29 Jun 02:27:47.411 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n19899:M 29 Jun 02:27:47.411 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never   /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n19899:M 29 Jun 02:27:47.411 * DB loaded from disk: 0.000 seconds\n19899:M 29 Jun 02:27:47.411 * The server is now ready to accept connections on port 22122  It's time to Download, Build and Install Dynomite Manager  cd ~\ngit clone git@github.com:Netflix/dynomite-manager.git\ncd dynomite-manager-1/\n./gradlew clean build  IF works you will see something like this:  :dynomitemanager:processResources\n:dynomitemanager:classes\n:dynomitemanager:writeManifestProperties\n:dynomitemanager:jar\n:dynomitemanager:assemble\n:dynomitemanager-web:compileJava UP-TO-DATE\n:dynomitemanager-web:processResources UP-TO-DATE\n:dynomitemanager-web:classes UP-TO-DATE\n:dynomitemanager-web:writeManifestProperties\n:dynomitemanager-web:war\nDownload https://jcenter.bintray.com/xerces/xercesImpl/2.4.0/xercesImpl-2.4.0.pom\nDownload https://jcenter.bintray.com/xerces/xercesImpl/2.4.0/xercesImpl-2.4.0.jar\n:dynomitemanager-web:assemble\n:collectNetflixOSS\n:dynomitemanager:writeLicenseHeader\n:dynomitemanager:licenseMain\nMissing header in: dynomitemanager/src/main/resources/log4j.properties\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/AwsInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/DefaultVpcInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/LocalInstanceEnvIdentity.java\nMissing header in: dynomitemanager/src/main/java/com/netflix/dynomitemanager/identity/InstanceEnvIdentity.java\n:dynomitemanager:licenseTest UP-TO-DATE\n:dynomitemanager:license\n:dynomitemanager:compileTestJava UP-TO-DATE\n:dynomitemanager:processTestResources UP-TO-DATE\n:dynomitemanager:testClasses UP-TO-DATE\n:dynomitemanager:test UP-TO-DATE\n:dynomitemanager:check\n:dynomitemanager:build\n:dynomitemanager-web:writeLicenseHeader\n:dynomitemanager-web:licenseMain UP-TO-DATE\n:dynomitemanager-web:licenseTest UP-TO-DATE\n:dynomitemanager-web:license UP-TO-DATE\n:dynomitemanager-web:compileTestJava UP-TO-DATE\n:dynomitemanager-web:processTestResources UP-TO-DATE\n:dynomitemanager-web:testClasses UP-TO-DATE\n:dynomitemanager-web:test UP-TO-DATE\n:dynomitemanager-web:check UP-TO-DATE\n:dynomitemanager-web:build\n\nBUILD SUCCESSFUL\n\nTotal time: 2 mins 7.695 secs\n\nThis build could be faster, please consider using the Gradle Daemon: https://docs.gradle.org/2.12/userguide/gradle_daemon.html\n[ec2-user@ip-172-31-14-210 dynomite-manager-1]$   Now we need add the startup script for Dynomite-Manager. Let' create the file first and them add content:  sudo touch /etc/init.d/dynomite-manager\nsudo vim /etc/init.d/dynomite-manager  /etc/init.d/dynomite-manager  #!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: java\n\nexport JAVA_HOME=/home/ec2-user/jdk1.8.0_45\nexport JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\nexport PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\nexport DM_CASSANDRA_CLUSTER_SEEDS= Ip1,ip2,ip3 \n\nexport ASG_NAME= asg_dynomite \nexport EC2_REGION= us-west-2 \nexport AUTO_SCALE_GROUP= asg_dynomite \nexport NETFLIX_APP= sg_asg_dynomite_florida \n\nstart() {\n   echo  Starting Dynomite Manager... \n   cd /home/ec2-user/dynomite-manager-1/\n   /home/ec2-user/dynomite-manager-1/gradlew jettyRun   /logs/system/dynomite-manager/dynomite-manager.log   \n}\n\nstop() {\n   echo  stoping Dynomite Manager...  \n   PID=`ps -ef | grep gradlew | awk '{print $2}' ORS=' ' | awk '{print $1}'`\n   if [[   !=   $PID  ]]; then\n      echo  killing $PID \n      sudo kill -9 $PID\n   fi\n}\n\ndebug() {\n   echo  Starting Dynomite Manager for DEBUG... \n   cd /home/ec2-user/dynomite-manager-1/\n   export GRADLE_OPTS= -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=n \n   ./gradlew jettyRun     \n}\n\n\ncase  $1  in start )\n  start\n;; debug )\n  debug\n;;\n  stop )\n  stop\n;;\n*)\n\necho $ Usage: $0 {start|stop|debug} \nRETVAL=1\nesac\nexit 0  You need set your comma separeted Cassandra seeds on DM_CASSANDRA_CLUSTER_SEEDS var.\nWe also need add permissions and need to enable this script to auto boot up with the box.  sudo chmod +x /etc/init.d/dynomite-manager\nsudo chkconfig dynomite-manager on  To make sure it works you can check it.  sudo chkconfig --list  You should see dynomite Manager on the list.  [ec2-user@ip-172-31-20-132 ~]$ sudo chkconfig --list\nacpid           0:off   1:off   2:on    3:on    4:on    5:on    6:off\natd             0:off   1:off   2:off   3:on    4:on    5:on    6:off\nauditd          0:off   1:off   2:on    3:on    4:on    5:on    6:off\nblk-availability    0:off   1:on    2:on    3:on    4:on    5:on    6:off\ncassandra       0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncgconfig        0:off   1:off   2:off   3:off   4:off   5:off   6:off\ncgred           0:off   1:off   2:off   3:off   4:off   5:off   6:off\ncloud-config    0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-final     0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-init      0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncloud-init-local    0:off   1:off   2:on    3:on    4:on    5:on    6:off\ncrond           0:off   1:off   2:on    3:on    4:on    5:on    6:off\ndynomite        0:off   1:off   2:on    3:on    4:on    5:on    6:off\ndynomite-manager    0:off   1:off   2:on    3:on    4:on    5:on    6:off\nip6tables       0:off   1:off   2:on    3:on    4:on    5:on    6:off\niptables        0:off   1:off   2:on    3:on    4:on    5:on    6:off\nirqbalance      0:off   1:off   2:on    3:on    4:on    5:on    6:off\nlvm2-monitor    0:off   1:on    2:on    3:on    4:on    5:on    6:off\nmdmonitor       0:off   1:off   2:on    3:on    4:on    5:on    6:off\nmessagebus      0:off   1:off   2:on    3:on    4:on    5:on    6:off\nnetconsole      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nnetfs           0:off   1:off   2:off   3:on    4:on    5:on    6:off\nnetwork         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nnfs             0:off   1:off   2:off   3:off   4:off   5:off   6:off\nnfslock         0:off   1:off   2:off   3:on    4:on    5:on    6:off\nntpd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nntpdate         0:off   1:off   2:on    3:on    4:on    5:on    6:off\npsacct          0:off   1:off   2:off   3:off   4:off   5:off   6:off\nquota_nld       0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrdisc           0:off   1:off   2:off   3:off   4:off   5:off   6:off\nredis_22122     0:off   1:off   2:on    3:on    4:on    5:on    6:off\nredis_6379      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrngd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nrpcbind         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nrpcgssd         0:off   1:off   2:off   3:on    4:on    5:on    6:off\nrpcsvcgssd      0:off   1:off   2:off   3:off   4:off   5:off   6:off\nrsyslog         0:off   1:off   2:on    3:on    4:on    5:on    6:off\nsaslauthd       0:off   1:off   2:off   3:off   4:off   5:off   6:off\nsendmail        0:off   1:off   2:on    3:on    4:on    5:on    6:off\nsshd            0:off   1:off   2:on    3:on    4:on    5:on    6:off\nudev-post       0:off   1:on    2:on    3:on    4:on    5:on    6:off\n[ec2-user@ip-172-31-20-132 ~]$   Now we need Download and Install Cassandra. We also will need to setup the schemas with CQL and add some start up script as well.  \nBEWARE this is a simpe imstalation in order to you TRY OUT Dynomite manager. This is a single cassandra. You should install a cassandra CLUSTER in your PROD env.   Download and Install Cassandra  cd ~\nwget https://archive.apache.org/dist/cassandra/2.1.9/apache-cassandra-2.1.9-bin.tar.gz\ntar -xzvf apache-cassandra-2.1.9-bin.tar.gz\nrm -rf apache-cassandra-2.1.9-bin.tar.gz  Create the Dynomite Manager Schemas. First we need start cassandra.  /home/ec2-user/apache-cassandra-2.1.9/\nbin/cassandra     Them we needto creathe de CQL file.  touch dynomite-manager.cql\nvim dynomite-manager.cql  With this content:   \nCREATE KEYSPACE dyno_bootstrap WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '3'}  AND durable_writes = true;\n\nCREATE TABLE dyno_bootstrap.tokens (\n    key text PRIMARY KEY,\n     Id  text,\n     appId  text,\n     availabilityZone  text,\n    datacenter text,\n     elasticIP  text,\n    hostname text,\n     instanceId  text,\n    location text,\n     token  text,\n    updatetime timeuuid\n) WITH COMPACT STORAGE\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = '{ keys : ALL ,  rows_per_partition : NONE }'\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 256\n    AND read_repair_chance = 1.0\n    AND speculative_retry = 'NONE';\nCREATE INDEX tokens_appid_idx ON dyno_bootstrap.tokens ( appId );\n\nCREATE TABLE dyno_bootstrap.locks (\n    key blob,\n    column1 text,\n    value blob,\n    PRIMARY KEY (key, column1)\n) WITH COMPACT STORAGE\n    AND CLUSTERING ORDER BY (column1 ASC)\n    AND bloom_filter_fp_chance = 0.01\n    AND caching = '{ keys : ALL ,  rows_per_partition : NONE }'\n    AND comment = ''\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n    AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n    AND dclocal_read_repair_chance = 0.0\n    AND default_time_to_live = 0\n    AND gc_grace_seconds = 864000\n    AND max_index_interval = 2048\n    AND memtable_flush_period_in_ms = 0\n    AND min_index_interval = 256\n    AND read_repair_chance = 1.0\n    AND speculative_retry = 'NONE';  And them Import on CQL  [ec2-user@ip-172-31-14-210 apache-cassandra-2.1.9]$ bin/cqlsh\nConnected to Test Cluster at 127.0.0.1:9042.\n[cqlsh 5.0.1 | Cassandra 2.1.14 | CQL spec 3.2.1 | Native protocol v3]\nUse HELP for help.\ncqlsh  SOURCE 'dynomite-manager.cql'\ncqlsh    OK. Now we need to create a startup script for Cassandra.  sudo touch /etc/init.d/cassandra\nsudo vim /etc/init.d/cassandra  With this content:  #!/bin/bash\n# chkconfig: 2345 95 20\n# description: This script does some stuff\n# processname: java\n\nstart() {\n   echo  Starting cassandra... \n   export JAVA_HOME=/home/ec2-user/jdk1.8.0_45\n   export JRE_HOME=/home/ec2-user/jdk1.8.0_45/jre\n   export PATH=$PATH:/home/ec2-user/jdk1.8.0_45/bin:/home/ec2-user/jdk1.8.0_45/jre/bin\n\n   cd /home/ec2-user/apache-cassandra-2.1.9\n   bin/cassandra start   \n}\n\nstop() {\n   echo  stop \n   PID=`ps aux | grep cassandra | grep -v grep | awk '{print $2}'`\n   if [[   !=   $PID  ]]; then\n      echo  killing $PID \n      sudo kill -9 $PID\n   fi\n}\n\ncase  $1  in start)\n  start\n;;\n  stop)\n  stop\n;;\n*)\n\necho $ Usage: $0 {start|stop} \nRETVAL=1\nesac\nexit 0  We need add permissions to execute and add to the boot up of the box.  sudo chmod +x /etc/init.d/cassandra\nsudo chkconfig cassandra on  Now we need move some files around and create some dirs. I'm doing this to make dynomite work with default settings.  \nIf you want you can change the configs to point to other folders.   sudo mkdir -p /logs/system/dynomite-manager/\nsudo mkdir -p /apps/dynomite/conf/\nsudo mkdir -p /apps/dynomite/bin/\nsudo mkdir -p /mnt/data/nfredis/\nsudo mkdir -p /logs/system/\nsudo mkdir -p /apps/nfredis/bin/\nsudo mkdir -p /logs/system/dynomite/\n\nsudo cp /home/ec2-user/dynomite/bin/kill_dynomite.sh /apps/dynomite/bin/\nsudo cp /home/ec2-user/dynomite/bin/launch_dynomite.sh /apps/dynomite/bin/\nsudo cp ~/dynomite/src/dynomite /apps/dynomite/bin/\nsudo cp ~/dynomite/src/*.* /apps/dynomite/bin/\nsudo cp ~/dynomite/conf/dynomite.pem /apps/dynomite/conf/dynomite.pem\nsudo cp ~/dynomite/conf/recon_key.pem /apps/dynomite/conf/\nsudo cp ~/dynomite/conf/recon_iv.pem /apps/dynomite/conf/\n\n#sudo cp /home/ec2-user/dynomite/bin/core_affinity.sh /apps/dynomite/bin/core_affinity.sh\nsudo cp /home/ec2-user/dynomite-manager-1/scripts/core_affinity-centos.sh /apps/dynomite/bin/core_affinity.sh\nsudo chmod +x /apps/dynomite/bin/core_affinity.sh\n\nsudo touch /apps/nfredis/bin/launch_nfredis.sh\nsudo vim /apps/nfredis/bin/launch_nfredis.sh\n#!/bin/bash\nsudo service redis_22122 start\n\nsudo chmod +x /apps/nfredis/bin/launch_nfredis.sh\nsudo touch /apps/nfredis/bin/kill_redis.sh\n\nsudo vim /apps/nfredis/bin/kill_redis.sh\n#!/bin/bash\nsudo service redis_22122 stop\n\nsudo chmod +x /apps/nfredis/bin/kill_redis.sh\n\nsudo mkdir -p /mnt/data/nfredis/\n\nsudo chmod -R 777 /logs/\nsudo chmod -R 777 /apps/\nsudo chmod -R 777 /mnt/  All Set. Now let's go to the AWS Ec2 console(https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:sort=desc:statusChecks) Right button of the mouse on the top of your instance and them Image menu -  Create Image.   Image Name: BASE_DYNOMITE_MANAGER  \nImage Description: BASE_DYNOMITE_MANAGER  \nHD: 20GB(Or anything you like it).", 
            "title": "Setup Dynomite and Dynomite Manager + Build an AMI"
        }, 
        {
            "location": "/Step-by-step-installation/#create-launch-config", 
            "text": "Go to the Launch Configuration(https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#LaunchConfigurations:) and create a LC:   Select My AMIs and them: BASE_DYNOMITE_MANAGER  \nSelect the Instance Type: m4.large(Or anything you like it).  \nAs Launch Configuration name: lc_dynomite_manager  \nIAM role: dynomite  \nMonitoring: Mark - Enable CloudWatch detailed monitoring  \nStorage: 20GB(Or anything you like it)  \nSecurity Group: Select - sg_asg_dynomite_florida  \nFor PEM file pick anyone you want it.", 
            "title": "Create Launch Config"
        }, 
        {
            "location": "/Step-by-step-installation/#create-asg", 
            "text": "Now is the time to create a Autoscaling group. Goto ASG(https://us-west-2.console.aws.amazon.com/ec2/autoscaling/home?region=us-west-2#AutoScalingGroups:view=details) and create a new one:  \nSelect the Launch Configuration: lc_dynomite_manager \nGroup name: asg_dynomite  \nGroup size: 3 \nVPC: Use the Default(Or anyone you like it) \nFor TAGS: key: name value: asg_dynomite  All Set! Now we can ssh in one of the 3 boxes to play with the REST operations!", 
            "title": "Create ASG"
        }, 
        {
            "location": "/Step-by-step-installation/#rest-endpoints", 
            "text": "curl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/takesnapshot\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/start\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/stop\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/cluster_describe\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/startstorageprocess\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/stopstorageprocess\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/backup\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/restore\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/get_seeds\ncurl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/status  More details here: https://github.com/Netflix/dynomite-manager/wiki/REST-API  We also can take a look at the dynomite-manager log using the bash alias dmlog.  [ec2-user@ip-172-31-20-132 bin]$ which dmlog\nalias dmlog='tail -f -n 2000 /logs/system/dynomite-manager/dynomite-manager.log'\n    /usr/bin/tail\n[ec2-user@ip-172-31-20-132 bin]$ sudo rm -rf /logs/system/dynomite-manager/dynomite-manager.log\n[ec2-user@ip-172-31-20-132 bin]$ \n[ec2-user@ip-172-31-20-132 bin]$ \n[ec2-user@ip-172-31-20-132 bin]$ cls\n\n[ec2-user@ip-172-31-20-132 bin]$ sudo /etc/init.d/dynomite-manager start\nStarting Dynomite Manager...\n[ec2-user@ip-172-31-20-132 bin]$ dmlog \nInferred project: dynomite-manager, version: 0.1.0-SNAPSHOT\nThe testJar task is deprecated.  Please place common test harness code in its own project and publish separately.\nPublication nebula not found in project :.\n[buildinfo] Not using buildInfo properties file for this build.\nPublication named 'nebula' does not exist for project ':' in task ':artifactoryPublish'.\n:dynomitemanager:compileJavawarning: [options] bootstrap class path not set in conjunction with -source 1.7\n1 warning\n\n:dynomitemanager:processResources UP-TO-DATE\n:dynomitemanager:classes\n:dynomitemanager:writeManifestProperties\n:dynomitemanager:jar\n:dynomitemanager-web:compileJava UP-TO-DATE\n:dynomitemanager-web:processResources UP-TO-DATE\n:dynomitemanager-web:classes UP-TO-DATE\n:dynomitemanager-web:jettyRunSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/root/.gradle/wrapper/dists/gradle-2.12-bin/avhnk0p45wmm16bas931at19r/gradle-2.12/lib/gradle-core-2.12.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/root/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-log4j12/1.7.2/7539c264413b9b1ff9841cd00058c974b7cd1ec9/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n\n2016-06-30 03:01:35 INFO  InjectedWebListener:112 - **Binding OSS Config classes.\n2016-06-30 03:01:36 WARN  URLConfigurationSource:120 - No URLs will be polled as dynamic configuration sources.\n2016-06-30 03:01:36 INFO  URLConfigurationSource:121 - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.\n2016-06-30 03:01:36 INFO  DynamicPropertyFactory:281 - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@39785b39\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/placement/availability-zone returns: us-west-2a\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/public-hostname returns: ec2-52-41-84-223.us-west-2.compute.amazonaws.com\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/public-ipv4 returns: 52.41.84.223\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/instance-id returns: i-e084504f\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/instance-type returns: m4.large\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/ returns: 02:af:8a:49:12:49/\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/ returns: 02:af:8a:49:12:49/\n2016-06-30 03:01:36 INFO  SystemUtils:62 - Calling URL API: http://169.254.169.254/latest/meta-data/network/interfaces/macs/02:af:8a:49:12:49/vpc-id returns: vpc-aeeb50cb\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:245 - vpc id for running instance: vpc-aeeb50cb\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:278 - Setting up Environmental Variables\n2016-06-30 03:01:36 INFO  DynomitemanagerConfiguration:286 - REGION set to us-west-2, ASG Name set to asg_dynomite1\n2016-06-30 03:01:36 INFO  PropertiesConfigSource:83 - No Dynomitemanager.properties. Ignore!\n2016-06-30 03:01:36 INFO  PropertiesConfigSource:83 - No Dynomitemanager.properties. Ignore!\n2016-06-30 03:01:37 INFO  SimpleThreadPool:267 - Job execution threads will use class loader of thread: main\n2016-06-30 03:01:37 INFO  SchedulerSignalerImpl:60 - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\n2016-06-30 03:01:37 INFO  QuartzScheduler:220 - Quartz Scheduler v.1.7.3 created.\n2016-06-30 03:01:37 INFO  RAMJobStore:139 - RAMJobStore initialized.\n2016-06-30 03:01:37 INFO  StdSchedulerFactory:1240 - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'\n2016-06-30 03:01:37 INFO  StdSchedulerFactory:1244 - Quartz scheduler version: 1.7.3\n2016-06-30 03:01:37 INFO  QuartzScheduler:2075 - JobFactory set to: com.netflix.dynomitemanager.sidecore.scheduler.GuiceJobFactory@3875b3c9\n2016-06-30 03:01:37 INFO  InstanceDataDAOCassandra:351 - BOOT_CLUSTER = cass_dyno, KS_NAME = dyno_bootstrap\n2016-06-30 03:01:37 INFO  CountingConnectionPoolMonitor:194 - AddHost: 127.0.0.1\n2016-06-30 03:01:37 INFO  ConnectionPoolMBeanManager:53 - Registering mbean: com.netflix.MonitoredResources:type=ASTYANAX,name=MyConnectionPool,ServiceType=connectionpool\n2016-06-30 03:01:38 INFO  UpdateChecker:86 - New update(s) found: 1.8.5 [http://www.terracotta.org/kit/reflector?kitID=default pageID=QuartzChangeLog]\n2016-06-30 03:01:38 INFO  InstanceIdentity:136 - My token: 3530913378\n2016-06-30 03:01:38 INFO  FloridaServer:79 - Initializing Florida Server now ...\n2016-06-30 03:01:38 INFO  AWSMembership:265 - Fetch current permissions for vpc env of running instance\n2016-06-30 03:01:38 INFO  FloridaServer:103 - Running TuneTask and updating configuration.\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:136 - dyn_o_mite:\n  dyn_listen: 0.0.0.0:8101\n  data_store: 0\n  listen: 0.0.0.0:8102\n  dyn_seed_provider: florida_provider\n  servers:\n  - 127.0.0.1:22122:1\n  tokens: '3530913378'\n  auto_eject_hosts: true\n  rack: asg_dynomite1\n  distribution: vnode\n  gos_interval: 10000\n  hash: murmur\n  preconnect: true\n  server_retry_timeout: 30000\n  timeout: 5000\n  secure_server_option: datacenter\n  datacenter: us-west-2\n  read_consistency: DC_ONE\n  write_consistency: DC_ONE\n  pem_key_file: /apps/dynomite/conf/dynomite.pem\n\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:250 - totalMem:8178632 Setting Redis storage max mem to 6081480\n2016-06-30 03:01:38 INFO  FloridaStandardTuner:164 - Updating Redis conf: /apps/nfredis/conf/redis.conf\n2016-06-30 03:01:38 INFO  FloridaServer:112 - Restore is disabled.\n2016-06-30 03:01:38 INFO  FloridaServer:121 - Cold bootstraping, launching dynomite and storage process.\n2016-06-30 03:01:38 INFO  FloridaProcessManager:74 - Starting dynomite server joinRing:true\n2016-06-30 03:01:43 ERROR FloridaProcessManager:99 - Unable to start Dynomite server. Error code: 1\n2016-06-30 03:01:43 INFO  FloridaProcessManager:124 - std_out: MBUF_SIZE=16384\nALLOC_MSGS=200000\n\ndynomite pid: \ntaskset: invalid PID argument: '2,5,6'\nredis pid: 8124\ntaskset: failed to set pid 8124's affinity: Invalid argument\npid 8124's current affinity list: 0,1\n\n2016-06-30 03:01:43 INFO  FloridaProcessManager:125 - std_err: \n2016-06-30 03:01:44 INFO  RedisStorageProxy:351 - Checking if Redis needs to be resetted to master\n2016-06-30 03:01:44 INFO  ProxyAndStorageResetTask:74 - Checking Dynomite's status\n2016-06-30 03:01:44 INFO  ProxyAndStorageResetTask:94 - Dynomite is up and running\n2016-06-30 03:01:44 INFO  FloridaServer:142 - Starting task scheduler\n2016-06-30 03:01:44 INFO  QuartzScheduler:472 - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.\n2016-06-30 03:01:44 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-30 03:01:44 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=false, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsed to check (micros): 40004\n2016-06-30 03:01:44 INFO  AWSMembership:265 - Fetch current permissions for vpc env of running instance", 
            "title": "REST endpoints"
        }, 
        {
            "location": "/Step-by-step-installation/#troubleshooting", 
            "text": "", 
            "title": "Troubleshooting:"
        }, 
        {
            "location": "/Step-by-step-installation/#make-sure-you-have-all-this-os_env-vars", 
            "text": "export ASG_NAME= asg_dynomite \nexport AUTO_SCALE_GROUP= asg_dynomite \nexport EC2_REGION= us-west-2 \nexport NETFLIX_APP= sg_asg_dynomite_florida", 
            "title": "Make sure you have all this OS_ENV vars:"
        }, 
        {
            "location": "/Step-by-step-installation/#get_seeds", 
            "text": "curl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/get_seeds  016-06-23 23:44:32 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-23 23:44:32 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=true, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsted to check (micros): 12779\n2016-06-23 23:44:43 ERROR DynomiteAdmin:194 - Cannot find the Seeds\n2016-06-23 23:44:47 INFO  ProcessMonitorTask:165 - Running checkProxyProcess command: ps -ef | grep  '[/]apps/dynomite/bin/dynomite'\n2016-06-23 23:44:47 INFO  ProcessMonitorTask:102 - ProcessMonitor state: InstanceState{isSideCarProcessAlive=true, isBootstrapping=false, isStorageProxyAlive=true, isStorageProxyProcessAlive=true, isStorageAlive=true, isHealthy=true, isProcessMonitoringSuspended=false}, time elapsted to check (micros): 7216   Make sure the ASG ash 3 instances  Make sure you have the right dynomite.yml config in place", 
            "title": "get_seeds"
        }, 
        {
            "location": "/Step-by-step-installation/#s3_backup", 
            "text": "curl -v http://localhost:8080/dynomitemanager-web/REST/v1/admin/s3restore  ON S3: 1383429731\nRestore: 1286668800000  2016-06-24 02:26:56 INFO  FloridaProcessManager:168 - Dynomite server has been stopped\n2016-06-24 02:26:56 INFO  StorageProcessManager:126 - Stopping Storage process ....\n2016-06-24 02:26:59 WARN  JedisUtils:112 - All retries to connect to host:127.0.0.1 port:8102 failed.\n2016-06-24 02:26:59 INFO  JedisUtils:54 - Unable to connect\n2016-06-24 02:26:59 ERROR BoundedExponentialRetryCallable:64 - Retry #1 for: Failed Jedis connect host:127.0.0.1 port:22122 failed.\n2016-06-24 02:27:01 INFO  StorageProcessManager:148 - Storage process has been stopped\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:190 - Date to restore to: 20101010\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:125 - Restoring data from S3.\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:137 - S3 Bucket Name: dynomite-backup\n2016-06-24 02:27:01 INFO  RestoreFromS3Task:138 - Key in Bucket: backup/us-west-2/asg_dynomite/1383429731/1286668800000\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:166 - AmazonServiceException; request made it to Amazon S3, but was rejected with an error \n2016-06-24 02:27:02 ERROR RestoreFromS3Task:168 - Error Message:    The specified key does not exist. (Service: Amazon S3; Status Code: 404; Error Code: NoSuchKey; Request ID: DA23FBFCA68F27FE)\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:169 - HTTP Status Code: 404\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:170 - AWS Error Code:   NoSuchKey\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:171 - Error Type:       Client\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:172 - Request ID:       DA23FBFCA68F27FE\n2016-06-24 02:27:02 ERROR RestoreFromS3Task:111 - S3 Restore not successful: Starting storage process without loading data.   BEWARE of the DATE diff you need have file based on time diff. Check RestoreFromS3Task.java  Need have permissions on: /mnt/data/", 
            "title": "s3_backup"
        }, 
        {
            "location": "/Step-by-step-installation/#position-must-be-0", 
            "text": "2016-06-25 01:18:09 ERROR RetryableCallable:72 - Retry #1 for: position must be  = 0\n2016-06-25 01:18:09 ERROR RetryableCallable:75 - Exception --  java.lang.IllegalArgumentException: position must be  = 0\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\n    at com.netflix.dynomitemanager.sidecore.utils.TokenManager.initialToken(TokenManager.java:47)\n    at com.netflix.dynomitemanager.sidecore.utils.TokenManager.createToken(TokenManager.java:75)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$GetNewToken.retriableCall(InstanceIdentity.java:245)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$GetNewToken.retriableCall(InstanceIdentity.java:220)\n    at com.netflix.dynomitemanager.sidecore.utils.RetryableCallable.call(RetryableCallable.java:59)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity.init(InstanceIdentity.java:134)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity. init (InstanceIdentity.java:86)\n    at com.netflix.dynomitemanager.identity.InstanceIdentity$$FastClassByGuice$$17e6ff76.newInstance( generated )\n    at com.google.inject.internal.cglib.reflect.$FastConstructor.newInstance(FastConstructor.java:40)\n    at com.google.inject.internal.DefaultConstructionProxyFactory$1.newInstance(DefaultConstructionProxyFactory.java:60)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:85)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:254)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1031)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.Scopes$1$1.get(Scopes.java:65)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:40)\n    at com.google.inject.internal.SingleParameterInjector.inject(SingleParameterInjector.java:38)\n    at com.google.inject.internal.SingleParameterInjector.getAll(SingleParameterInjector.java:62)\n    at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:84)\n    at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:254)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1031)\n    at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\n    at com.google.inject.Scopes$1$1.get(Scopes.java:65)\n    at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:40)\n    at com.google.inject.internal.InjectorImpl$4$1.call(InjectorImpl.java:978)\n    at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1024)\n    at com.google.inject.internal.InjectorImpl$4.get(InjectorImpl.java:974)\n    at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1013)\n    at com.netflix.dynomitemanager.defaultimpl.InjectedWebListener.getInjector(InjectedWebListener.java:83)\n    at com.google.inject.servlet.GuiceServletContextListener.contextInitialized(GuiceServletContextListener.java:45)\n    at org.mortbay.jetty.handler.ContextHandler.startContext(ContextHandler.java:548)\n    at org.mortbay.jetty.servlet.Context.startContext(Context.java:136)\n    at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1272)\n    at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:517)\n    at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:489)\n    at org.gradle.api.plugins.jetty.internal.JettyPluginWebAppContext.doStart(JettyPluginWebAppContext.java:112)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)\n    at org.mortbay.jetty.Server.doStart(Server.java:224)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.gradle.api.plugins.jetty.internal.Jetty6PluginServer.start(Jetty6PluginServer.java:111)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJettyInternal(AbstractJettyRunTask.java:238)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJetty(AbstractJettyRunTask.java:191)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.start(AbstractJettyRunTask.java:162)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.doExecute(AnnotationProcessingTaskFactory.java:227)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:220)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:209)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:585)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:568)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)\n    at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)\n    at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\n    at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)\n    at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50)\n    at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:25)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:110)\n    at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23)\n    at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43)\n    at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30)\n    at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:154)\n    at org.gradle.internal.Factories$1.create(Factories.java:22)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:52)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:151)\n    at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:32)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:99)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:93)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:62)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:93)\n    at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:82)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.run(InProcessBuildActionExecuter.java:94)\n    at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:43)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:45)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28)\n    at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43)\n    at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:169)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:33)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:22)\n    at org.gradle.launcher.Main.doAction(Main.java:33)\n    at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35)\n    at org.gradle.launcher.GradleMain.main(GradleMain.java:23)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30)\n    at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129)\n    at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61)  This means you are not running Dynomite Manager whithin an ASG(Auto Scalling Group), Once you do it, shoudl fix the problem.", 
            "title": "position must be &gt;= 0"
        }, 
        {
            "location": "/Step-by-step-installation/#unable-to-get-group-id-or-group-name", 
            "text": "2016-06-30 02:36:16 ERROR AWSMembership:191 - unable to get group-id for group-name=asg_dynomite1 vpc-id=vpc-aeeb50cb\n2016-06-30 02:36:16 ERROR Task:99 - Couldnt execute the task because of The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: b211f8ad-150d-4148-9d14-9b08fcce93a5)\ncom.amazonaws.AmazonServiceException: The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: b211f8ad-150d-4148-9d14-9b08fcce93a5)\n    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1383)\n    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:902)\n    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:607)\n    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:376)\n    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:338)\n    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:287)\n    at com.amazonaws.services.ec2.AmazonEC2Client.invoke(AmazonEC2Client.java:11128)\n    at com.amazonaws.services.ec2.AmazonEC2Client.authorizeSecurityGroupIngress(AmazonEC2Client.java:1019)\n    at com.netflix.dynomitemanager.sidecore.aws.AWSMembership.addACL(AWSMembership.java:153)\n    at com.netflix.dynomitemanager.sidecore.aws.UpdateSecuritySettings.execute(UpdateSecuritySettings.java:70)\n    at com.netflix.dynomitemanager.sidecore.scheduler.Task.execute(Task.java:93)\n    at org.quartz.core.JobRunShell.run(JobRunShell.java:199)\n    at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:546)\n\n\n2016-06-30 02:44:10 INFO  FloridaServer:79 - Initializing Florida Server now ...\n2016-06-30 02:44:10 INFO  AWSMembership:269 - Fetch current permissions for vpc env of running instance\n2016-06-30 02:44:10 ERROR AWSMembership:191 - unable to get group-id for group-name=asg_dynomite vpc-id=vpc-aeeb50cb\n2016-06-30 02:44:10 ERROR Task:99 - Couldnt execute the task because of The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: 85d82dba-e3b2-4e30-9087-00a84371ed69)\ncom.amazonaws.AmazonServiceException: The request must contain the parameter groupName or groupId (Service: AmazonEC2; Status Code: 400; Error Code: MissingParameter; Request ID: 85d82dba-e3b2-4e30-9087-00a84371ed69)\n    at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1383)\n    at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:902)\n    at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:607)\n    at com.amazonaws.http.AmazonHttpClient.doExecute(AmazonHttpClient.java:376)\n    at com.amazonaws.http.AmazonHttpClient.executeWithTimer(AmazonHttpClient.java:338)\n    at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:287)\n    at com.amazonaws.services.ec2.AmazonEC2Client.invoke(AmazonEC2Client.java:11128)\n    at com.amazonaws.services.ec2.AmazonEC2Client.authorizeSecurityGroupIngress(AmazonEC2Client.java:1019)\n    at com.netflix.dynomitemanager.sidecore.aws.AWSMembership.addACL(AWSMembership.java:153)\n    at com.netflix.dynomitemanager.sidecore.aws.UpdateSecuritySettings.execute(UpdateSecuritySettings.java:70)\n    at com.netflix.dynomitemanager.sidecore.scheduler.Task.execute(Task.java:93)\n    at com.netflix.dynomitemanager.sidecore.scheduler.TaskScheduler.runTaskNow(TaskScheduler.java:98)\n    at com.netflix.dynomitemanager.FloridaServer.initialize(FloridaServer.java:84)\n    at com.netflix.dynomitemanager.defaultimpl.InjectedWebListener.getInjector(InjectedWebListener.java:83)\n    at com.google.inject.servlet.GuiceServletContextListener.contextInitialized(GuiceServletContextListener.java:45)\n    at org.mortbay.jetty.handler.ContextHandler.startContext(ContextHandler.java:548)\n    at org.mortbay.jetty.servlet.Context.startContext(Context.java:136)\n    at org.mortbay.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1272)\n    at org.mortbay.jetty.handler.ContextHandler.doStart(ContextHandler.java:517)\n    at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:489)\n    at org.gradle.api.plugins.jetty.internal.JettyPluginWebAppContext.doStart(JettyPluginWebAppContext.java:112)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)\n    at org.mortbay.jetty.Server.doStart(Server.java:224)\n    at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)\n    at org.gradle.api.plugins.jetty.internal.Jetty6PluginServer.start(Jetty6PluginServer.java:111)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJettyInternal(AbstractJettyRunTask.java:238)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.startJetty(AbstractJettyRunTask.java:191)\n    at org.gradle.api.plugins.jetty.AbstractJettyRunTask.start(AbstractJettyRunTask.java:162)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:75)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.doExecute(AnnotationProcessingTaskFactory.java:227)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:220)\n    at org.gradle.api.internal.project.taskfactory.AnnotationProcessingTaskFactory$StandardTaskAction.execute(AnnotationProcessingTaskFactory.java:209)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:585)\n    at org.gradle.api.internal.AbstractTask$TaskActionWrapper.execute(AbstractTask.java:568)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)\n    at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)\n    at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)\n    at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)\n    at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:203)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter$EventFiringTaskWorker.execute(DefaultTaskGraphExecuter.java:185)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:66)\n    at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:50)\n    at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:25)\n    at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:110)\n    at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.access$000(DefaultBuildExecuter.java:23)\n    at org.gradle.execution.DefaultBuildExecuter$1.proceed(DefaultBuildExecuter.java:43)\n    at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:37)\n    at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:30)\n    at org.gradle.initialization.DefaultGradleLauncher$4.run(DefaultGradleLauncher.java:154)\n    at org.gradle.internal.Factories$1.create(Factories.java:22)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:52)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:151)\n    at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:32)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:99)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:93)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:62)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:93)\n    at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:82)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.run(InProcessBuildActionExecuter.java:94)\n    at org.gradle.tooling.internal.provider.ExecuteBuildActionRunner.run(ExecuteBuildActionRunner.java:28)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:43)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:75)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:45)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:51)\n    at org.gradle.launcher.exec.DaemonUsageSuggestingBuildActionExecuter.execute(DaemonUsageSuggestingBuildActionExecuter.java:28)\n    at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:43)\n    at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:170)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237)\n    at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35)\n    at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206)\n    at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:169)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:33)\n    at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:22)\n    at org.gradle.launcher.Main.doAction(Main.java:33)\n    at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54)\n    at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35)\n    at org.gradle.launcher.GradleMain.main(GradleMain.java:23)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30)\n    at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:129)\n    at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61)  Make sure you have the OS env var called NETFLIX_APP pointing to the right Security Group name.", 
            "title": "Unable to get group-id or group-name"
        }, 
        {
            "location": "/Step-by-step-installation/#more-on-redis-persistence-check", 
            "text": "Look for the BGREWRITEAOF Command\nhttp://redis.io/topics/persistence", 
            "title": "More on Redis Persistence check"
        }, 
        {
            "location": "/Step-by-step-installation/#some-important-classes-for-configs", 
            "text": "InjectedWebListener\nDynomitemanagerConfiguration\nDynomiteAdmin\nFloridaProcessManager\nRedisStorageProxy\nSnapshotBackup\nInstanceProfileCredentialsProvider\nEC2MetadataClient", 
            "title": "Some important Classes for Configs:"
        }, 
        {
            "location": "/Token-Management/", 
            "text": "Dynomite vs Cassandra tokens\n\n\nDynomite and Cassandra share a lot of commonalities on the way they use tokens. The difference between the two is that Dynomite occupies the whole token range on a per rack basis, whereas Cassandra on a per zone basis (when using token static allocation and not virtual nodes). Therefore, tokens can repeat across racks and in the same datacenter. The rest of the token management is very much similar. In that perspective Dynomite-manager shares a lot of code with \nPriam\n, Netflix Cassandra sidecar.\n\n\nToken calculation\n\n\nDynomite-manager calculates the token of every node by looking at the number of slots (nodes), by which the token range is divided in the rack, and the position of the node. The tokens are then stored in an external data store along with application id, availability zone, datacenter, instance id, hostname, and elastic IP.  Since nodes are by nature volatile in the cloud, if a node gets replaced, Dynomite-manager in the new node queries the data store to find if a token was pre-generated. At Netflix, we leverage a Cassandra cluster to store this information.\n\n\nNode Replacement\n\n\nSince we run Dynomite on the cloud at any point of time a node can die. A new instance is booted in the same auto-scaling group. Dynomite-manager loads along with the Tomcat server. Dynomite-manager queries AWS to receive the list of nodes in the same auto-scaling group, and queries the external Cassandra cluster for the list of nodes along with their tokens. It compares the two and determines, which node has been terminated and marks the token as \ndead\n. It then self-assigns the \ndead\n token, and follows the warm up procedure so that there is no data loss. After the warm up is complete, it starts Dynomite and the storage engine.\n\n\nDuring this process, Dyno is informed either through the discovery service that the node is down, or after N (N=10 by default) errors fails over to another node that has the same token in the same datacenter.\n\n\nToken Management\n\n\nAn external structured persistent data store system has to be used. This can be done by implementing the interface \nIAppsInstanceFactory\n.\nIf you plan to use Cassandra to handle the tokens the following KEYSPACE and TABLE definitions can be used:\n\n\nCREATE KEYSPACE dyno_bootstrap WITH replication = {'class': 'NetworkTopologyStrategy', 'eu-west': '3', 'us-east': '3', 'us-west': '3', 'us-west-2': '3'}  AND durable_writes = true;\n\nCREATE TABLE dyno_bootstrap.tokens (\n    key text PRIMARY KEY,\n    \"Id\" text,\n    \"appId\" text,\n    \"availabilityZone\" text,\n    datacenter text,\n     \"elasticIP\" text,\n    hostname text,\n    \"instanceId\" text,\n    location text,\n    \"token\" text,\n    updatetime timeuuid\n)\n\nCREATE TABLE dyno_bootstrap.locks (\n  key blob,\n  column1 text,\n  value blob,\nPRIMARY KEY (key, column1)\n) WITH COMPACT STORAGE\n  AND CLUSTERING ORDER BY (column1 ASC)\n  AND bloom_filter_fp_chance = 0.01\n  AND caching = '{\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"}'\n  AND comment = ''\n  AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n  AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n  AND dclocal_read_repair_chance = 0.0\n  AND default_time_to_live = 0\n  AND gc_grace_seconds = 864000\n  AND max_index_interval = 2048\n  AND memtable_flush_period_in_ms = 0\n  AND min_index_interval = 256\n  AND read_repair_chance = 1.0\n  AND speculative_retry = 'NONE';\n\n\n\nThe client code can be found in \nCassandraInstranceFactory\n.\n\n\nHow can I see the token assigned token on each Dynomite node\n\n\nREST API to Dynomite manager\n\n\n/get_seeds\n: responds with the hostnames and tokens\n\n\n/cluster_describe\n: responds with a JSON file of the cluster level information\n\n\n/status\n: returns the status of the processes managed by Dynomite-manager and itself, including the token of the node\n\n\nDynomite's YAML\n\n\nThe YAML contains the tokens. Dynomite-manager re-writes the YAML whenever a new node joins the ring, such that it is always up to date.", 
            "title": "Token Management"
        }, 
        {
            "location": "/Token-Management/#dynomite-vs-cassandra-tokens", 
            "text": "Dynomite and Cassandra share a lot of commonalities on the way they use tokens. The difference between the two is that Dynomite occupies the whole token range on a per rack basis, whereas Cassandra on a per zone basis (when using token static allocation and not virtual nodes). Therefore, tokens can repeat across racks and in the same datacenter. The rest of the token management is very much similar. In that perspective Dynomite-manager shares a lot of code with  Priam , Netflix Cassandra sidecar.", 
            "title": "Dynomite vs Cassandra tokens"
        }, 
        {
            "location": "/Token-Management/#token-calculation", 
            "text": "Dynomite-manager calculates the token of every node by looking at the number of slots (nodes), by which the token range is divided in the rack, and the position of the node. The tokens are then stored in an external data store along with application id, availability zone, datacenter, instance id, hostname, and elastic IP.  Since nodes are by nature volatile in the cloud, if a node gets replaced, Dynomite-manager in the new node queries the data store to find if a token was pre-generated. At Netflix, we leverage a Cassandra cluster to store this information.", 
            "title": "Token calculation"
        }, 
        {
            "location": "/Token-Management/#node-replacement", 
            "text": "Since we run Dynomite on the cloud at any point of time a node can die. A new instance is booted in the same auto-scaling group. Dynomite-manager loads along with the Tomcat server. Dynomite-manager queries AWS to receive the list of nodes in the same auto-scaling group, and queries the external Cassandra cluster for the list of nodes along with their tokens. It compares the two and determines, which node has been terminated and marks the token as  dead . It then self-assigns the  dead  token, and follows the warm up procedure so that there is no data loss. After the warm up is complete, it starts Dynomite and the storage engine.  During this process, Dyno is informed either through the discovery service that the node is down, or after N (N=10 by default) errors fails over to another node that has the same token in the same datacenter.", 
            "title": "Node Replacement"
        }, 
        {
            "location": "/Token-Management/#token-management", 
            "text": "An external structured persistent data store system has to be used. This can be done by implementing the interface  IAppsInstanceFactory .\nIf you plan to use Cassandra to handle the tokens the following KEYSPACE and TABLE definitions can be used:  CREATE KEYSPACE dyno_bootstrap WITH replication = {'class': 'NetworkTopologyStrategy', 'eu-west': '3', 'us-east': '3', 'us-west': '3', 'us-west-2': '3'}  AND durable_writes = true;\n\nCREATE TABLE dyno_bootstrap.tokens (\n    key text PRIMARY KEY,\n    \"Id\" text,\n    \"appId\" text,\n    \"availabilityZone\" text,\n    datacenter text,\n     \"elasticIP\" text,\n    hostname text,\n    \"instanceId\" text,\n    location text,\n    \"token\" text,\n    updatetime timeuuid\n)\n\nCREATE TABLE dyno_bootstrap.locks (\n  key blob,\n  column1 text,\n  value blob,\nPRIMARY KEY (key, column1)\n) WITH COMPACT STORAGE\n  AND CLUSTERING ORDER BY (column1 ASC)\n  AND bloom_filter_fp_chance = 0.01\n  AND caching = '{\"keys\":\"ALL\", \"rows_per_partition\":\"NONE\"}'\n  AND comment = ''\n  AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'}\n  AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'}\n  AND dclocal_read_repair_chance = 0.0\n  AND default_time_to_live = 0\n  AND gc_grace_seconds = 864000\n  AND max_index_interval = 2048\n  AND memtable_flush_period_in_ms = 0\n  AND min_index_interval = 256\n  AND read_repair_chance = 1.0\n  AND speculative_retry = 'NONE';  The client code can be found in  CassandraInstranceFactory .", 
            "title": "Token Management"
        }, 
        {
            "location": "/Token-Management/#how-can-i-see-the-token-assigned-token-on-each-dynomite-node", 
            "text": "", 
            "title": "How can I see the token assigned token on each Dynomite node"
        }, 
        {
            "location": "/Token-Management/#rest-api-to-dynomite-manager", 
            "text": "/get_seeds : responds with the hostnames and tokens  /cluster_describe : responds with a JSON file of the cluster level information  /status : returns the status of the processes managed by Dynomite-manager and itself, including the token of the node", 
            "title": "REST API to Dynomite manager"
        }, 
        {
            "location": "/Token-Management/#dynomites-yaml", 
            "text": "The YAML contains the tokens. Dynomite-manager re-writes the YAML whenever a new node joins the ring, such that it is always up to date.", 
            "title": "Dynomite's YAML"
        }, 
        {
            "location": "/_Sidebar/", 
            "text": "[[Home]]  \n\n\n[[Features]]\n\n\n[[Cold Bootstraping]]  \n\n\n[[Service Discovery and Healthcheck]] \n\n\n[[Monitoring and Insights Integration]]\n\n\n[[Backups and Restores]]\n\n\n[[REST API]]\n\n\n[[Getting Started]]\n\n\n[[Step by step installation]]\n\n\n[[Token Management]]\n\n\n[[AWS Deployment]]\n\n\n[[How to contribute]]\n\n\n[[FAQ]]", 
            "title": " Sidebar"
        }
    ]
}